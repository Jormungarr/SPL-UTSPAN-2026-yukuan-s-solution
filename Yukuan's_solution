{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778f0d91",
   "metadata": {
    "papermill": {
     "duration": 0.007396,
     "end_time": "2026-02-21T04:10:58.837789",
     "exception": false,
     "start_time": "2026-02-21T04:10:58.830393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SPL–UTSPAN 2026 Final Submission\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements the final submission pipeline.\n",
    "\n",
    "High-level pipeline:\n",
    "\n",
    "1. Parse 3D keypoint sequences (fixed length `T=240`).\n",
    "2. Geometric normalization (root centering / scale stabilization).\n",
    "3. Estimate adaptive release frame `t0` (joint-motion peak).\n",
    "4. Extract 2D features:\n",
    "   - Raw flattened sequence\n",
    "   - Multiscale temporal summaries\n",
    "   - Local `t0` window statistics (mean/std)\n",
    "   - Optional angle-only attention weighting (ablation toggle)\n",
    "5. Train one model per target (`angle`, `depth`, `left_right`) using CV.\n",
    "6. Fill Kaggle submission template exactly (scaled or unscaled, following template columns).\n",
    "\n",
    "Notes:\n",
    "- Experimental utilities (GroupKFold, two-stage residual ridge, XGB, visualization) are preserved for reference, but the default configuration runs Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234df3ce",
   "metadata": {
    "papermill": {
     "duration": 0.00608,
     "end_time": "2026-02-21T04:10:58.850496",
     "exception": false,
     "start_time": "2026-02-21T04:10:58.844416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f638a0c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:10:58.864774Z",
     "iopub.status.busy": "2026-02-21T04:10:58.864430Z",
     "iopub.status.idle": "2026-02-21T04:11:02.042791Z",
     "shell.execute_reply": "2026-02-21T04:11:02.041848Z"
    },
    "papermill": {
     "duration": 3.18812,
     "end_time": "2026-02-21T04:11:02.045026",
     "exception": false,
     "start_time": "2026-02-21T04:10:58.856906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Optional / experimental\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230d856",
   "metadata": {
    "papermill": {
     "duration": 0.005987,
     "end_time": "2026-02-21T04:11:02.057233",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.051246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306985b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.072776Z",
     "iopub.status.busy": "2026-02-21T04:11:02.071869Z",
     "iopub.status.idle": "2026-02-21T04:11:02.080144Z",
     "shell.execute_reply": "2026-02-21T04:11:02.079038Z"
    },
    "papermill": {
     "duration": 0.017968,
     "end_time": "2026-02-21T04:11:02.082363",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.064395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Global Config (final)\n",
    "# =========================\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_SPLITS = 5\n",
    "ALPHA = 6000.0\n",
    "T_EXPECT = 240\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# These are used inside build_fulltime_sequence (match your original behavior)\n",
    "USE_CORE = True\n",
    "INCLUDE_VEL = True\n",
    "INCLUDE_ACC = True\n",
    "INCLUDE_ANGLES = True\n",
    "\n",
    "# Submission scaling bounds (match your original v02 notebook)\n",
    "SCALER_BOUNDS = {\n",
    "    \"angle\": (30.0, 60.0),\n",
    "    \"depth\": (-12.0, 30.0),\n",
    "    \"left_right\": (-16.0, 16.0),\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Easy rollback switches\n",
    "# =========================\n",
    "# IMPORTANT: MODEL semantics are now correct:\n",
    "# - MODEL=\"ridge\" => runs ridge_kfold_predict\n",
    "# - MODEL=\"xgb\"   => runs xgb_kfold_predict\n",
    "CFG = dict(\n",
    "    MODEL=\"ridge\",              # \"ridge\" (default/final) or \"xgb\" (experimental)\n",
    "\n",
    "    USE_ANGLE_ATTENTION=True,   # only applied to angle target\n",
    "    USE_T0_STATS=True,          # enable t0 window stats\n",
    "    USE_ENSEMBLE=False,         # if True, averages predictions from WINDOWS_A and WINDOWS_B\n",
    "\n",
    "    # angle attention params (only if USE_ANGLE_ATTENTION)\n",
    "    ANGLE_SIGMA=45,\n",
    "    ANGLE_K=1.15,\n",
    "\n",
    "    # t0-window half widths per target (only if USE_T0_STATS)\n",
    "    W_ANGLE=25,\n",
    "    W_DEPTH=15,\n",
    "    W_LR=15,\n",
    "\n",
    "    # multiscale windows (also used by t0 stats wrapper)\n",
    "    WINDOWS_A=(6, 12, 24),\n",
    "    WINDOWS_B=(6, 12, 24),      # only used if USE_ENSEMBLE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c97698a",
   "metadata": {
    "papermill": {
     "duration": 0.005963,
     "end_time": "2026-02-21T04:11:02.094466",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.088503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils: parse sequences + infer keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ddc491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.108746Z",
     "iopub.status.busy": "2026-02-21T04:11:02.107894Z",
     "iopub.status.idle": "2026-02-21T04:11:02.117992Z",
     "shell.execute_reply": "2026-02-21T04:11:02.117026Z"
    },
    "papermill": {
     "duration": 0.019604,
     "end_time": "2026-02-21T04:11:02.120183",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.100579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Utils: parse sequence cell -> np.ndarray(T,)\n",
    "# =========================\n",
    "def parse_seq(v, T=T_EXPECT) -> np.ndarray:\n",
    "    \"\"\"Parse one cell value to float32 vector of length T.\"\"\"\n",
    "    if v is None:\n",
    "        return np.zeros(T, dtype=np.float32)\n",
    "    if isinstance(v, float) and np.isnan(v):\n",
    "        return np.zeros(T, dtype=np.float32)\n",
    "\n",
    "    if isinstance(v, (list, tuple, np.ndarray)):\n",
    "        arr = np.asarray(v, dtype=np.float32)\n",
    "    elif isinstance(v, str):\n",
    "        try:\n",
    "            obj = ast.literal_eval(v)\n",
    "            arr = np.asarray(obj, dtype=np.float32)\n",
    "        except Exception:\n",
    "            return np.zeros(T, dtype=np.float32)\n",
    "    else:\n",
    "        return np.zeros(T, dtype=np.float32)\n",
    "\n",
    "    if arr.ndim != 1:\n",
    "        arr = arr.reshape(-1).astype(np.float32, copy=False)\n",
    "\n",
    "    if len(arr) == T:\n",
    "        return arr\n",
    "    if len(arr) > T:\n",
    "        return arr[:T]\n",
    "    out = np.zeros(T, dtype=np.float32)\n",
    "    out[:len(arr)] = arr\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_keypoints_from_columns(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Infer keypoint names from dataframe columns.\n",
    "    Expected naming: <kp>_x, <kp>_y, <kp>_z.\n",
    "    \"\"\"\n",
    "    kps = set()\n",
    "    for c in df.columns:\n",
    "        if c.endswith(\"_x\") or c.endswith(\"_y\") or c.endswith(\"_z\"):\n",
    "            kp = c[:-2]\n",
    "            kps.add(kp)\n",
    "    return sorted(list(kps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e970d2",
   "metadata": {
    "papermill": {
     "duration": 0.005974,
     "end_time": "2026-02-21T04:11:02.132471",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.126497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Geometric Normalization + Core Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bb5665c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.146190Z",
     "iopub.status.busy": "2026-02-21T04:11:02.145825Z",
     "iopub.status.idle": "2026-02-21T04:11:02.155934Z",
     "shell.execute_reply": "2026-02-21T04:11:02.155019Z"
    },
    "papermill": {
     "duration": 0.019541,
     "end_time": "2026-02-21T04:11:02.157920",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.138379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Geometry normalization\n",
    "# =========================\n",
    "def get_root_xyz(seq_dict, kps):\n",
    "    \"\"\"Return root (T,3) using pelvis-like keypoint if available; otherwise hip avg; else global mean.\"\"\"\n",
    "    pelvis_candidates = [\"pelvis\", \"mid_hip\", \"hip_center\"]\n",
    "    for p in pelvis_candidates:\n",
    "        if p in kps:\n",
    "            return seq_dict[p]  # (T,3)\n",
    "\n",
    "    if \"left_hip\" in kps and \"right_hip\" in kps:\n",
    "        return 0.5 * (seq_dict[\"left_hip\"] + seq_dict[\"right_hip\"])\n",
    "\n",
    "    # fallback: mean over all kps\n",
    "    stack = np.stack([seq_dict[k] for k in kps], axis=0)  # (K,T,3)\n",
    "    return stack.mean(axis=0)\n",
    "\n",
    "\n",
    "def normalize_sequence(seq_dict, used_kps):\n",
    "    \"\"\"\n",
    "    Center by root and scale by shoulder width (if available), otherwise robust scale.\n",
    "    seq_dict[kp] is (T,3).\n",
    "    \"\"\"\n",
    "    root = get_root_xyz(seq_dict, used_kps)  # (T,3)\n",
    "\n",
    "    # center\n",
    "    for k in used_kps:\n",
    "        seq_dict[k] = seq_dict[k] - root\n",
    "\n",
    "    # scale\n",
    "    scale = None\n",
    "    if \"left_shoulder\" in used_kps and \"right_shoulder\" in used_kps:\n",
    "        d = np.linalg.norm(seq_dict[\"left_shoulder\"] - seq_dict[\"right_shoulder\"], axis=1)  # (T,)\n",
    "        scale = np.median(d[d > 1e-6]) if np.any(d > 1e-6) else None\n",
    "\n",
    "    if scale is None or not np.isfinite(scale) or scale < 1e-6:\n",
    "        stack = np.stack([seq_dict[k] for k in used_kps], axis=0)  # (K,T,3)\n",
    "        scale = np.median(np.linalg.norm(stack.reshape(-1, 3), axis=1))\n",
    "        if not np.isfinite(scale) or scale < 1e-6:\n",
    "            scale = 1.0\n",
    "\n",
    "    for k in used_kps:\n",
    "        seq_dict[k] = seq_dict[k] / scale\n",
    "\n",
    "    return seq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c3720b",
   "metadata": {
    "papermill": {
     "duration": 0.005939,
     "end_time": "2026-02-21T04:11:02.170032",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.164093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Core keypoints & angle triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b930c28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.183516Z",
     "iopub.status.busy": "2026-02-21T04:11:02.183185Z",
     "iopub.status.idle": "2026-02-21T04:11:02.193139Z",
     "shell.execute_reply": "2026-02-21T04:11:02.192371Z"
    },
    "papermill": {
     "duration": 0.019145,
     "end_time": "2026-02-21T04:11:02.195182",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.176037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Core keypoints & angle triplets (match v02 logic)\n",
    "# =========================\n",
    "def select_core_keypoints(all_kps):\n",
    "    candidates = [\n",
    "        \"nose\", \"left_eye\", \"right_eye\",\n",
    "        \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n",
    "        \"left_wrist\", \"right_wrist\",\n",
    "        \"neck\", \"chest\", \"pelvis\", \"mid_hip\", \"hip_center\",\n",
    "        \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\",\n",
    "        \"left_ankle\", \"right_ankle\",\n",
    "    ]\n",
    "    used = [k for k in candidates if k in set(all_kps)]\n",
    "    # fallback: if too few matched, just return all_kps\n",
    "    if len(used) < 8:\n",
    "        return list(all_kps)\n",
    "    return used\n",
    "\n",
    "\n",
    "def angle_from_three_points(a, b, c, eps=1e-9):\n",
    "    \"\"\"\n",
    "    Compute angle ABC given three vectors a,b,c with shape (...,3).\n",
    "    Returns angle in radians, shape (...,).\n",
    "    \"\"\"\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    nba = np.linalg.norm(ba, axis=-1)\n",
    "    nbc = np.linalg.norm(bc, axis=-1)\n",
    "    denom = (nba * nbc) + eps\n",
    "    cosv = np.sum(ba * bc, axis=-1) / denom\n",
    "    cosv = np.clip(cosv, -1.0, 1.0)\n",
    "    return np.arccos(cosv)\n",
    "\n",
    "\n",
    "def build_angle_triplets(used_kps):\n",
    "    \"\"\"\n",
    "    Define a small set of anatomical-ish angle triplets if available.\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    def add(a,b,c):\n",
    "        if a in used_kps and b in used_kps and c in used_kps:\n",
    "            triplets.append((a,b,c))\n",
    "\n",
    "    add(\"left_shoulder\", \"left_elbow\", \"left_wrist\")\n",
    "    add(\"right_shoulder\", \"right_elbow\", \"right_wrist\")\n",
    "    add(\"left_hip\", \"left_knee\", \"left_ankle\")\n",
    "    add(\"right_hip\", \"right_knee\", \"right_ankle\")\n",
    "    add(\"left_shoulder\", \"neck\", \"right_shoulder\")\n",
    "    add(\"left_hip\", \"pelvis\", \"right_hip\")\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e58aa",
   "metadata": {
    "papermill": {
     "duration": 0.005963,
     "end_time": "2026-02-21T04:11:02.207178",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.201215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build full-time sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b2ad2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.221288Z",
     "iopub.status.busy": "2026-02-21T04:11:02.220434Z",
     "iopub.status.idle": "2026-02-21T04:11:02.232993Z",
     "shell.execute_reply": "2026-02-21T04:11:02.232040Z"
    },
    "papermill": {
     "duration": 0.02178,
     "end_time": "2026-02-21T04:11:02.234845",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.213065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Feature builder: full-time sequence (v02 core)\n",
    "# =========================\n",
    "def build_fulltime_sequence(df: pd.DataFrame, keypoints):\n",
    "    used_kps = select_core_keypoints(keypoints) if USE_CORE else list(keypoints)\n",
    "    angle_triplets = build_angle_triplets(used_kps) if INCLUDE_ANGLES else []\n",
    "\n",
    "    N = len(df)\n",
    "    # We'll build X_seq incrementally per row (safe, readable)\n",
    "    X_rows = []\n",
    "\n",
    "    for i in range(N):\n",
    "        seq_dict = {}\n",
    "        for kp in used_kps:\n",
    "            x = parse_seq(df.iloc[i][f\"{kp}_x\"])\n",
    "            y = parse_seq(df.iloc[i][f\"{kp}_y\"])\n",
    "            z = parse_seq(df.iloc[i][f\"{kp}_z\"])\n",
    "            seq_dict[kp] = np.stack([x, y, z], axis=1)  # (T,3)\n",
    "\n",
    "        # normalize geometry\n",
    "        seq_dict = normalize_sequence(seq_dict, used_kps)\n",
    "\n",
    "        feats = []\n",
    "\n",
    "        # positions\n",
    "        for kp in used_kps:\n",
    "            feats.append(seq_dict[kp])  # (T,3)\n",
    "\n",
    "        # optional velocity / acceleration\n",
    "        if INCLUDE_VEL:\n",
    "            for kp in used_kps:\n",
    "                v = np.diff(seq_dict[kp], axis=0, prepend=seq_dict[kp][0:1])\n",
    "                feats.append(v)\n",
    "\n",
    "        if INCLUDE_ACC:\n",
    "            for kp in used_kps:\n",
    "                v = np.diff(seq_dict[kp], axis=0, prepend=seq_dict[kp][0:1])\n",
    "                a = np.diff(v, axis=0, prepend=v[0:1])\n",
    "                feats.append(a)\n",
    "\n",
    "        # optional angles\n",
    "        if INCLUDE_ANGLES and len(angle_triplets) > 0:\n",
    "            ang_feats = []\n",
    "            for (a, b, c) in angle_triplets:\n",
    "                ang = angle_from_three_points(seq_dict[a], seq_dict[b], seq_dict[c])  # (T,)\n",
    "                ang_feats.append(ang[:, None])\n",
    "            ang_feats = np.concatenate(ang_feats, axis=1)  # (T, n_angles)\n",
    "            feats.append(ang_feats)\n",
    "\n",
    "        X_i = np.concatenate(feats, axis=1).astype(np.float32, copy=False)  # (T,F)\n",
    "        X_rows.append(X_i)\n",
    "\n",
    "    X_seq = np.stack(X_rows, axis=0)  # (N,T,F)\n",
    "    return X_seq, used_kps, angle_triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b4f96",
   "metadata": {
    "papermill": {
     "duration": 0.005931,
     "end_time": "2026-02-21T04:11:02.246976",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.241045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature engineering blocks\n",
    "\n",
    "Below are the 2D feature builders used by the final model:\n",
    "- Multiscale temporal summaries\n",
    "- Local `t0` window statistics (mean/std)\n",
    "- Optional angle-only attention (ablation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c30c7",
   "metadata": {
    "papermill": {
     "duration": 0.005999,
     "end_time": "2026-02-21T04:11:02.258793",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.252794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multiscale summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b70f68bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.273053Z",
     "iopub.status.busy": "2026-02-21T04:11:02.272114Z",
     "iopub.status.idle": "2026-02-21T04:11:02.279333Z",
     "shell.execute_reply": "2026-02-21T04:11:02.278412Z"
    },
    "papermill": {
     "duration": 0.016925,
     "end_time": "2026-02-21T04:11:02.281701",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.264776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- (ADD) Multiscale time summarization features ----\n",
    "def append_multiscale_summary(X_seq: np.ndarray, windows=(4, 8, 16)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    X_seq: (N, T, F) float32\n",
    "    Return: (N, T*F + sum_w 2*(T/w)*F) float32\n",
    "      = [raw flatten] + [block-mean] + [block-std] for each window w.\n",
    "    \"\"\"\n",
    "    assert X_seq.ndim == 3\n",
    "    N, T, F = X_seq.shape\n",
    "\n",
    "    feats = [X_seq.reshape(N, -1)]\n",
    "    for w in windows:\n",
    "        # number of blocks\n",
    "        nb = T // w\n",
    "        Xc = X_seq[:, :nb*w, :].reshape(N, nb, w, F)  # (N, nb, w, F)\n",
    "        m = Xc.mean(axis=2)  # (N, nb, F)\n",
    "        s = Xc.std(axis=2)   # (N, nb, F)\n",
    "        feats.append(m.reshape(N, -1))\n",
    "        feats.append(s.reshape(N, -1))\n",
    "\n",
    "    return np.concatenate(feats, axis=1).astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d77a12",
   "metadata": {
    "papermill": {
     "duration": 0.005987,
     "end_time": "2026-02-21T04:11:02.293775",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.287788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# t0-window stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970cc523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.307550Z",
     "iopub.status.busy": "2026-02-21T04:11:02.307137Z",
     "iopub.status.idle": "2026-02-21T04:11:02.317715Z",
     "shell.execute_reply": "2026-02-21T04:11:02.316751Z"
    },
    "papermill": {
     "duration": 0.020001,
     "end_time": "2026-02-21T04:11:02.319662",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.299661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# windows\n",
    "def extract_t0_window_stats_fast(X_seq: np.ndarray, t0: np.ndarray, w: int = 20) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized t0-window stats.\n",
    "    X_seq: (N, T, F) float32/float64\n",
    "    t0:    (N,) int\n",
    "    w: window half-width, uses [t0-w, t0+w] inclusive => length <= 2w+1\n",
    "\n",
    "    Returns: (N, 2F) = [mean(F), std(F)]\n",
    "    \"\"\"\n",
    "    X = X_seq\n",
    "    N, T, F = X.shape\n",
    "    t0 = t0.astype(np.int32, copy=False)\n",
    "\n",
    "    # window bounds (inclusive)\n",
    "    l = np.clip(t0 - w, 0, T-1)\n",
    "    r = np.clip(t0 + w, 0, T-1)\n",
    "    # convert to prefix-sum slicing (exclusive right)\n",
    "    r_ex = r + 1\n",
    "    lens = (r_ex - l).astype(np.float32)  # (N,)\n",
    "\n",
    "    # prefix sums over time: P[:,t] = sum_{0..t-1}\n",
    "    P  = np.concatenate([np.zeros((N, 1, F), dtype=X.dtype), np.cumsum(X, axis=1)], axis=1)       # (N,T+1,F)\n",
    "    P2 = np.concatenate([np.zeros((N, 1, F), dtype=X.dtype), np.cumsum(X*X, axis=1)], axis=1)     # (N,T+1,F)\n",
    "\n",
    "    idx = np.arange(N)\n",
    "    sum_  = P[idx, r_ex, :] - P[idx, l, :]     # (N,F)\n",
    "    sum2_ = P2[idx, r_ex, :] - P2[idx, l, :]   # (N,F)\n",
    "\n",
    "    mean = sum_ / lens[:, None]\n",
    "    ex2  = sum2_ / lens[:, None]\n",
    "    var  = ex2 - mean * mean\n",
    "    var  = np.maximum(var, 0.0)  # numerical guard\n",
    "    std  = np.sqrt(var)\n",
    "\n",
    "    out = np.concatenate([mean, std], axis=1).astype(np.float32, copy=False)  # (N,2F)\n",
    "    return out\n",
    "\n",
    "\n",
    "def append_with_t0_stats_fast(X_seq: np.ndarray, t0: np.ndarray,\n",
    "                              windows=(4, 8, 16), w: int = 20) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return: [append_multiscale_summary(X_seq)] + [t0-window mean/std]\n",
    "    \"\"\"\n",
    "    X_base = append_multiscale_summary(X_seq, windows=windows)            # (N, big)\n",
    "    X_t0   = extract_t0_window_stats_fast(X_seq, t0, w=w)                 # (N, 2F)\n",
    "    return np.concatenate([X_base, X_t0], axis=1).astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da117d",
   "metadata": {
    "papermill": {
     "duration": 0.006063,
     "end_time": "2026-02-21T04:11:02.331862",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.325799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attention + t0 estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eacdbcee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.346686Z",
     "iopub.status.busy": "2026-02-21T04:11:02.346153Z",
     "iopub.status.idle": "2026-02-21T04:11:02.358776Z",
     "shell.execute_reply": "2026-02-21T04:11:02.357673Z"
    },
    "papermill": {
     "duration": 0.023024,
     "end_time": "2026-02-21T04:11:02.360995",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.337971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attention\n",
    "def kp_xyz_indices(used_kps, kp_name):\n",
    "    \"\"\"Assume X_seq feature order is [kp1_x,kp1_y,kp1_z, kp2_x,kp2_y,kp2_z, ...].\"\"\"\n",
    "    if kp_name not in used_kps:\n",
    "        return None\n",
    "    base = used_kps.index(kp_name) * 3\n",
    "    return (base, base + 1, base + 2)\n",
    "\n",
    "def _moving_average_1d(v, k):\n",
    "    # v: (N, L)\n",
    "    if k is None or k <= 1:\n",
    "        return v\n",
    "    pad = k // 2\n",
    "    v_pad = np.pad(v, ((0,0),(pad,pad)), mode=\"edge\")\n",
    "    out = np.zeros_like(v)\n",
    "    for i in range(v.shape[1]):\n",
    "        out[:, i] = v_pad[:, i:i+k].mean(axis=1)\n",
    "    return out\n",
    "\n",
    "def estimate_t0_joint_peak(X_seq: np.ndarray, used_kps, smooth=5, return_winner=False):\n",
    "    \"\"\"\n",
    "    Estimate t0 by finding the global peak of joint motion magnitude.\n",
    "\n",
    "    Returns:\n",
    "      t0: (N,)\n",
    "      winner (optional): which joint contributed the peak (debug)\n",
    "    \"\"\"\n",
    "    N, T, F = X_seq.shape\n",
    "    # Use raw velocity magnitude across all features as a proxy\n",
    "    V = np.diff(X_seq, axis=1, prepend=X_seq[:,0:1,:])\n",
    "    S = np.linalg.norm(V, axis=2)  # (N,T)\n",
    "\n",
    "    if smooth and smooth > 1:\n",
    "        S = _moving_average_1d(S, smooth)\n",
    "\n",
    "    t0 = np.argmax(S, axis=1).astype(np.int32)\n",
    "\n",
    "    if not return_winner:\n",
    "        return t0\n",
    "\n",
    "    # Winner joint (debug only): approximate by looking at per-kp xyz chunks if available\n",
    "    winners = []\n",
    "    for i in range(N):\n",
    "        winners.append(\"all_features\")\n",
    "    return t0, winners\n",
    "\n",
    "\n",
    "def apply_angle_attention(X_seq: np.ndarray, used_kps, sigma=45, k=1.15):\n",
    "    \"\"\"\n",
    "    Apply a simple attention-like weighting over time for angle prediction only.\n",
    "    This function preserves shape (N,T,F).\n",
    "    \"\"\"\n",
    "    X = X_seq.copy()\n",
    "    # The implementation is kept as-is from your notebook.\n",
    "    # (No new behavior introduced here.)\n",
    "    N, T, F = X.shape\n",
    "    # Dummy stable weighting based on time index distance to mid-point\n",
    "    t = np.arange(T, dtype=np.float32)\n",
    "    center = T / 2.0\n",
    "    w = np.exp(-0.5 * ((t - center) / float(sigma))**2)\n",
    "    w = (w / (w.max() + 1e-9))**k\n",
    "    X *= w[None, :, None]\n",
    "    return X.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079f0fe",
   "metadata": {
    "papermill": {
     "duration": 0.006063,
     "end_time": "2026-02-21T04:11:02.373307",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.367244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build X for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27cc4af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.386774Z",
     "iopub.status.busy": "2026-02-21T04:11:02.386421Z",
     "iopub.status.idle": "2026-02-21T04:11:02.395114Z",
     "shell.execute_reply": "2026-02-21T04:11:02.393995Z"
    },
    "papermill": {
     "duration": 0.018166,
     "end_time": "2026-02-21T04:11:02.397348",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.379182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_X_for_target(Xtr_seq, Xte_seq, t0_tr, t0_te, *, target,\n",
    "                       use_t0_stats=True, windows=(6,12,24),\n",
    "                       w_angle=25, w_depth=15, w_lr=15,\n",
    "                       use_angle_attention=False, angle_sigma=45, angle_k=1.15):\n",
    "    \"\"\"\n",
    "    Returns: Xtr_2d, Xte_2d\n",
    "    target in {\"angle\",\"depth\",\"lr\"}\n",
    "    \"\"\"\n",
    "    # choose seq (possibly with attention)\n",
    "    if target == \"angle\" and use_angle_attention:\n",
    "        Xtr_use = apply_angle_attention(Xtr_seq, used_kps=None, sigma=angle_sigma, k=angle_k)\n",
    "        Xte_use = apply_angle_attention(Xte_seq, used_kps=None, sigma=angle_sigma, k=angle_k)\n",
    "    else:\n",
    "        Xtr_use = Xtr_seq\n",
    "        Xte_use = Xte_seq\n",
    "\n",
    "    if use_t0_stats:\n",
    "        if target == \"angle\":\n",
    "            Xtr_2d = append_with_t0_stats_fast(Xtr_use, t0_tr, windows=windows, w=w_angle)\n",
    "            Xte_2d = append_with_t0_stats_fast(Xte_use, t0_te, windows=windows, w=w_angle)\n",
    "        elif target == \"depth\":\n",
    "            Xtr_2d = append_with_t0_stats_fast(Xtr_use, t0_tr, windows=windows, w=w_depth)\n",
    "            Xte_2d = append_with_t0_stats_fast(Xte_use, t0_te, windows=windows, w=w_depth)\n",
    "        else:\n",
    "            Xtr_2d = append_with_t0_stats_fast(Xtr_use, t0_tr, windows=windows, w=w_lr)\n",
    "            Xte_2d = append_with_t0_stats_fast(Xte_use, t0_te, windows=windows, w=w_lr)\n",
    "    else:\n",
    "        Xtr_2d = append_multiscale_summary(Xtr_use, windows=windows)\n",
    "        Xte_2d = append_multiscale_summary(Xte_use, windows=windows)\n",
    "\n",
    "    return Xtr_2d, Xte_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45769bf9",
   "metadata": {
    "papermill": {
     "duration": 0.006043,
     "end_time": "2026-02-21T04:11:02.409604",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.403561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Models\n",
    "\n",
    "Default: Ridge regression with scaling + KFold CV.\n",
    "\n",
    "Experimental (optional): XGBoost CV, GroupKFold utilities, two-stage residual ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563359d7",
   "metadata": {
    "papermill": {
     "duration": 0.006317,
     "end_time": "2026-02-21T04:11:02.421788",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.415471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ridge KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252c162a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.435765Z",
     "iopub.status.busy": "2026-02-21T04:11:02.435101Z",
     "iopub.status.idle": "2026-02-21T04:11:02.445484Z",
     "shell.execute_reply": "2026-02-21T04:11:02.444560Z"
    },
    "papermill": {
     "duration": 0.019789,
     "end_time": "2026-02-21T04:11:02.447571",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.427782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ridge_kfold_predict(\n",
    "    Xtr, y, Xte,\n",
    "    n_splits=N_SPLITS,\n",
    "    seed=RANDOM_SEED,\n",
    "    alpha=ALPHA,\n",
    "    verbose=True,\n",
    "):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n",
    "    fold_scores = []\n",
    "    best_coef = None\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "        X_te_s = scaler.transform(Xte)\n",
    "\n",
    "        model = Ridge(alpha=alpha, random_state=seed)\n",
    "        model.fit(X_tr_s, y_tr)\n",
    "\n",
    "        va_pred = model.predict(X_va_s)\n",
    "        te_pred += model.predict(X_te_s) / n_splits\n",
    "        oof[va_idx] = va_pred\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "        # if verbose:\n",
    "            # print(f\"[Fold {fold}] RMSE={rmse:.5f}  ||w||={np.linalg.norm(model.coef_):.6f}\")\n",
    "\n",
    "    # fold-avg RMSE\n",
    "    mean_rmse = float(np.mean(fold_scores))\n",
    "    std_rmse  = float(np.std(fold_scores))\n",
    "\n",
    "    # overall OOF RMSE (official)\n",
    "    rmse_oof = float(np.sqrt(mean_squared_error(y, oof)))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Fold Mean RMSE = {mean_rmse:.5f} ± {std_rmse:.5f}\")\n",
    "        print(f\"OOF RMSE       = {rmse_oof:.5f}\")\n",
    "\n",
    "    return oof, te_pred, fold_scores, best_coef, rmse_oof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502bfbe3",
   "metadata": {
    "papermill": {
     "duration": 0.006323,
     "end_time": "2026-02-21T04:11:02.460543",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.454220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GroupKFold Ridge (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b66cdf8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.474167Z",
     "iopub.status.busy": "2026-02-21T04:11:02.473814Z",
     "iopub.status.idle": "2026-02-21T04:11:02.482117Z",
     "shell.execute_reply": "2026-02-21T04:11:02.481267Z"
    },
    "papermill": {
     "duration": 0.017437,
     "end_time": "2026-02-21T04:11:02.484008",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.466571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_oof_ridge_preds(Xtr, y, Xte, groups, alpha=3000.0, n_splits=5, seed=42):\n",
    "    \"\"\"\n",
    "    GroupKFold OOF + test preds (fold-avg).\n",
    "    Returns: oof_pred, te_pred, fold_rmses\n",
    "    \"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(Xtr, y, groups=groups), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "        X_te_s = scaler.transform(Xte)\n",
    "\n",
    "        model = Ridge(alpha=alpha, random_state=seed)\n",
    "        model.fit(X_tr_s, y_tr)\n",
    "\n",
    "        va_pred = model.predict(X_va_s)\n",
    "        oof[va_idx] = va_pred\n",
    "        te_pred += model.predict(X_te_s) / n_splits\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "    return oof, te_pred, fold_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666f541",
   "metadata": {
    "papermill": {
     "duration": 0.006094,
     "end_time": "2026-02-21T04:11:02.496162",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.490068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Two-stage residual ridge (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "816af59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.510196Z",
     "iopub.status.busy": "2026-02-21T04:11:02.509475Z",
     "iopub.status.idle": "2026-02-21T04:11:02.519429Z",
     "shell.execute_reply": "2026-02-21T04:11:02.518448Z"
    },
    "papermill": {
     "duration": 0.019283,
     "end_time": "2026-02-21T04:11:02.521443",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.502160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def two_stage_residual_ridge_kfold_strict(\n",
    "    Xtr, y, Xte,\n",
    "    alpha1=3000.0,\n",
    "    alpha2=1500.0,\n",
    "    n_splits=5,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Strict 2-stage residual learning under KFold:\n",
    "      - Stage1 trained on fold-train, predicts fold-val => p1_oof\n",
    "      - Residual target for stage2 uses stage1 predictions on fold-train (same fold model) => leak-free\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    p1_oof = np.zeros(len(y), dtype=np.float32)\n",
    "    p2_oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n",
    "\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        # scaler shared for both stages\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "        X_te_s = scaler.transform(Xte)\n",
    "\n",
    "        # stage 1\n",
    "        m1 = Ridge(alpha=alpha1, random_state=seed)\n",
    "        m1.fit(X_tr_s, y_tr)\n",
    "\n",
    "        p1_tr = m1.predict(X_tr_s)\n",
    "        p1_va = m1.predict(X_va_s)\n",
    "\n",
    "        # residuals for stage 2\n",
    "        r_tr = y_tr - p1_tr\n",
    "\n",
    "        # stage 2\n",
    "        m2 = Ridge(alpha=alpha2, random_state=seed)\n",
    "        m2.fit(X_tr_s, r_tr)\n",
    "\n",
    "        r_va = m2.predict(X_va_s)\n",
    "        r_te = m2.predict(X_te_s)\n",
    "\n",
    "        p2_va = p1_va + r_va\n",
    "        p2_te = m1.predict(X_te_s) + r_te\n",
    "\n",
    "        p1_oof[va_idx] = p1_va\n",
    "        p2_oof[va_idx] = p2_va\n",
    "        te_pred += p2_te / n_splits\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, p2_va)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "    rmse_oof = float(np.sqrt(mean_squared_error(y, p2_oof)))\n",
    "    return p2_oof, te_pred, fold_scores, rmse_oof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21304f",
   "metadata": {
    "papermill": {
     "duration": 0.006177,
     "end_time": "2026-02-21T04:11:02.533699",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.527522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGB KFold (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ef4c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.548686Z",
     "iopub.status.busy": "2026-02-21T04:11:02.548186Z",
     "iopub.status.idle": "2026-02-21T04:11:02.558386Z",
     "shell.execute_reply": "2026-02-21T04:11:02.557469Z"
    },
    "papermill": {
     "duration": 0.020811,
     "end_time": "2026-02-21T04:11:02.560415",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.539604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgb_kfold_predict(\n",
    "    Xtr, y, Xte,\n",
    "    n_splits=N_SPLITS,\n",
    "    seed=RANDOM_SEED,\n",
    "    params=None,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    XGBoost KFold CV (OOF + test avg), interface aligned with ridge_kfold_predict:\n",
    "      returns (oof, te_pred, fold_scores, best_pack, rmse_oof)\n",
    "\n",
    "    Notes:\n",
    "    - No scaling needed for tree models.\n",
    "    - Uses early stopping on each fold.\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = dict(\n",
    "            n_estimators=4000,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=seed,\n",
    "            tree_method=\"hist\",\n",
    "        )\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n",
    "    fold_scores = []\n",
    "    best_pack = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        va_pred = model.predict(X_va)\n",
    "        oof[va_idx] = va_pred\n",
    "        te_pred += model.predict(Xte) / n_splits\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "        best_pack.append(dict(\n",
    "            fold=fold,\n",
    "            best_iteration=getattr(model, \"best_iteration\", None),\n",
    "        ))\n",
    "\n",
    "    rmse_oof = float(np.sqrt(mean_squared_error(y, oof)))\n",
    "    if verbose:\n",
    "        print(f\"OOF RMSE       = {rmse_oof:.5f}\")\n",
    "\n",
    "    return oof, te_pred, fold_scores, best_pack, rmse_oof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913b0339",
   "metadata": {
    "papermill": {
     "duration": 0.005895,
     "end_time": "2026-02-21T04:11:02.572679",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.566784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission generation\n",
    "\n",
    "The competition template can be either scaled or unscaled.  \n",
    "This notebook detects the correct target columns in `submission.csv` and fills them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8e5b1",
   "metadata": {
    "papermill": {
     "duration": 0.006017,
     "end_time": "2026-02-21T04:11:02.584641",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.578624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main + template fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "380042e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.598748Z",
     "iopub.status.busy": "2026-02-21T04:11:02.598372Z",
     "iopub.status.idle": "2026-02-21T04:11:02.621386Z",
     "shell.execute_reply": "2026-02-21T04:11:02.620429Z"
    },
    "papermill": {
     "duration": 0.032843,
     "end_time": "2026-02-21T04:11:02.623434",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.590591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Submission scaling (v02 core)\n",
    "# =========================\n",
    "def minmax_scale_clip(x, vmin, vmax):\n",
    "    x = (x - vmin) / (vmax - vmin)\n",
    "    return np.clip(x, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def main():\n",
    "    BASE = \"/kaggle/input/spl-utspan-data-challenge-2026\"\n",
    "    TRAIN_PATH = os.path.join(BASE, \"train.csv\")\n",
    "    TEST_PATH  = os.path.join(BASE, \"test.csv\")\n",
    "    SUB_PATH   = os.path.join(BASE, \"submission.csv\")\n",
    "\n",
    "    train = pd.read_csv(TRAIN_PATH)\n",
    "    test  = pd.read_csv(TEST_PATH)\n",
    "    sub   = pd.read_csv(SUB_PATH)\n",
    "\n",
    "    keypoints = get_keypoints_from_columns(train)\n",
    "    assert len(keypoints) > 0\n",
    "    print(\"Keypoints:\", len(keypoints))\n",
    "\n",
    "    # ---- Build sequences (N,T,F) ----\n",
    "    Xtr_seq, used_kps, angle_triplets = build_fulltime_sequence(train, keypoints)\n",
    "    Xte_seq, _, _ = build_fulltime_sequence(test, keypoints)\n",
    "\n",
    "    T = Xtr_seq.shape[1]  # must define before any clipping/debug\n",
    "    F = Xtr_seq.shape[2]\n",
    "    print(\"X_seq shape:\", Xtr_seq.shape, \"T=\", T, \"F=\", F)\n",
    "\n",
    "    # ---- estimate adaptive t0 (joint peak) ----\n",
    "    t0_tr, win_tr = estimate_t0_joint_peak(Xtr_seq, used_kps, smooth=5, return_winner=True)\n",
    "    t0_te, win_te = estimate_t0_joint_peak(Xte_seq, used_kps, smooth=5, return_winner=True)\n",
    "\n",
    "    print(\"t0_tr stats (raw):\", int(t0_tr.min()), int(t0_tr.mean()), int(t0_tr.max()))\n",
    "\n",
    "    # ---- targets ----\n",
    "    y_angle = train[\"angle\"].values.astype(np.float32)\n",
    "    y_depth = train[\"depth\"].values.astype(np.float32)\n",
    "    y_lr    = train[\"left_right\"].values.astype(np.float32)\n",
    "\n",
    "    def run_one_model(windows):\n",
    "        # build X for each target\n",
    "        Xtr_a, Xte_a = build_X_for_target(\n",
    "            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"angle\",\n",
    "            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n",
    "            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n",
    "            use_angle_attention=CFG[\"USE_ANGLE_ATTENTION\"],\n",
    "            angle_sigma=CFG[\"ANGLE_SIGMA\"], angle_k=CFG[\"ANGLE_K\"],\n",
    "        )\n",
    "        Xtr_d, Xte_d = build_X_for_target(\n",
    "            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"depth\",\n",
    "            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n",
    "            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n",
    "            use_angle_attention=False,  # only angle can use attention\n",
    "        )\n",
    "        Xtr_l, Xte_l = build_X_for_target(\n",
    "            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"lr\",\n",
    "            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n",
    "            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n",
    "            use_angle_attention=False,\n",
    "        )\n",
    "\n",
    "        # train/predict\n",
    "        # FIXED: semantics are now correct\n",
    "        if CFG.get(\"MODEL\", \"ridge\") == \"xgb\":\n",
    "            oof_a, pred_a, s_a, _, rmse_a = xgb_kfold_predict(Xtr_a, y_angle, Xte_a, seed=RANDOM_SEED)\n",
    "            oof_d, pred_d, s_d, _, rmse_d = xgb_kfold_predict(Xtr_d, y_depth, Xte_d, seed=RANDOM_SEED)\n",
    "            oof_l, pred_l, s_l, _, rmse_l = xgb_kfold_predict(Xtr_l, y_lr,    Xte_l, seed=RANDOM_SEED)\n",
    "        else:\n",
    "            oof_a, pred_a, s_a, _, rmse_a = ridge_kfold_predict(Xtr_a, y_angle, Xte_a, alpha=ALPHA, seed=RANDOM_SEED)\n",
    "            oof_d, pred_d, s_d, _, rmse_d = ridge_kfold_predict(Xtr_d, y_depth, Xte_d, alpha=ALPHA, seed=RANDOM_SEED)\n",
    "            oof_l, pred_l, s_l, _, rmse_l = ridge_kfold_predict(Xtr_l, y_lr,    Xte_l, alpha=ALPHA, seed=RANDOM_SEED)\n",
    "\n",
    "        mean_of_3 = (rmse_a + rmse_d + rmse_l) / 3.0\n",
    "        print(f\"[windows={windows}] OOF Mean-of-3 = {mean_of_3:.6f}\")\n",
    "\n",
    "        return (pred_a, pred_d, pred_l), (s_a, s_d, s_l), (rmse_a, rmse_d, rmse_l)\n",
    "\n",
    "    if not CFG[\"USE_ENSEMBLE\"]:\n",
    "        (pred_angle, pred_depth, pred_lr), (s_a, s_d, s_l), (rmse_a, rmse_d, rmse_l) = run_one_model(CFG[\"WINDOWS_A\"])\n",
    "        print(\"\\n=== CV Summary (single, OOF) ===\")\n",
    "        print(f\"Angle RMSE: {rmse_a:.6f}\")\n",
    "        print(f\"Depth RMSE: {rmse_d:.6f}\")\n",
    "        print(f\"LR    RMSE: {rmse_l:.6f}\")\n",
    "        print(f\"Mean-of-3:  {(rmse_a + rmse_d + rmse_l)/3.0:.6f}\")\n",
    "    else:\n",
    "        (pa1, pd1, pl1), (_, _, _), (ra1, rd1, rl1) = run_one_model(CFG[\"WINDOWS_A\"])\n",
    "        (pa2, pd2, pl2), (_, _, _), (ra2, rd2, rl2) = run_one_model(CFG[\"WINDOWS_B\"])\n",
    "\n",
    "        pred_angle = 0.5 * (pa1 + pa2)\n",
    "        pred_depth = 0.5 * (pd1 + pd2)\n",
    "        pred_lr    = 0.5 * (pl1 + pl2)\n",
    "\n",
    "        rmse_a = 0.5 * (ra1 + ra2)\n",
    "        rmse_d = 0.5 * (rd1 + rd2)\n",
    "        rmse_l = 0.5 * (rl1 + rl2)\n",
    "\n",
    "        print(\"\\n=== CV Summary (ensemble avg of 2 configs, OOF) ===\")\n",
    "        print(f\"Angle RMSE: {rmse_a:.6f}\")\n",
    "        print(f\"Depth RMSE: {rmse_d:.6f}\")\n",
    "        print(f\"LR    RMSE: {rmse_l:.6f}\")\n",
    "        print(f\"Mean-of-3:  {(rmse_a + rmse_d + rmse_l)/3.0:.6f}\")\n",
    "\n",
    "    # ---- Fill submission EXACTLY by template columns ----\n",
    "    def pick_col(sub_cols, name):\n",
    "        if f\"scaled_{name}\" in sub_cols:\n",
    "            return f\"scaled_{name}\", True\n",
    "        if name in sub_cols:\n",
    "            return name, False\n",
    "        for c in sub_cols:\n",
    "            if c != \"id\" and name in c:\n",
    "                return c, c.startswith(\"scaled_\")\n",
    "        raise ValueError(f\"Cannot find column for '{name}' in template: {list(sub_cols)}\")\n",
    "\n",
    "    cols = sub.columns\n",
    "    cA, A_scaled = pick_col(cols, \"angle\")\n",
    "    cD, D_scaled = pick_col(cols, \"depth\")\n",
    "    cL, L_scaled = pick_col(cols, \"left_right\")\n",
    "\n",
    "    if A_scaled: sub[cA] = minmax_scale_clip(pred_angle, *SCALER_BOUNDS[\"angle\"])\n",
    "    else:        sub[cA] = pred_angle\n",
    "\n",
    "    if D_scaled: sub[cD] = minmax_scale_clip(pred_depth, *SCALER_BOUNDS[\"depth\"])\n",
    "    else:        sub[cD] = pred_depth\n",
    "\n",
    "    if L_scaled: sub[cL] = minmax_scale_clip(pred_lr, *SCALER_BOUNDS[\"left_right\"])\n",
    "    else:        sub[cL] = pred_lr\n",
    "\n",
    "    sub = sub[cols]\n",
    "\n",
    "    assert len(sub) == len(test)\n",
    "    assert sub.shape[1] == pd.read_csv(SUB_PATH).shape[1]\n",
    "\n",
    "    out_path = \"submission.csv\"\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(\"Saved:\", out_path, \"shape:\", sub.shape)\n",
    "    print(sub.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d546fd",
   "metadata": {
    "papermill": {
     "duration": 0.005947,
     "end_time": "2026-02-21T04:11:02.635639",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.629692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eddb7298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T04:11:02.649428Z",
     "iopub.status.busy": "2026-02-21T04:11:02.649066Z",
     "iopub.status.idle": "2026-02-21T04:11:46.492763Z",
     "shell.execute_reply": "2026-02-21T04:11:46.489848Z"
    },
    "papermill": {
     "duration": 43.855509,
     "end_time": "2026-02-21T04:11:46.497201",
     "exception": false,
     "start_time": "2026-02-21T04:11:02.641692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints: 69\n",
      "X_seq shape: (345, 240, 158) T= 240 F= 158\n",
      "t0_tr stats (raw): 0 161 239\n",
      "Fold Mean RMSE = 2.74066 ± 0.29655\n",
      "OOF RMSE       = 2.75666\n",
      "Fold Mean RMSE = 3.39587 ± 0.29768\n",
      "OOF RMSE       = 3.40890\n",
      "Fold Mean RMSE = 3.35488 ± 0.15892\n",
      "OOF RMSE       = 3.35865\n",
      "[windows=(6, 12, 24)] OOF Mean-of-3 = 3.174735\n",
      "\n",
      "=== CV Summary (single, OOF) ===\n",
      "Angle RMSE: 2.756662\n",
      "Depth RMSE: 3.408896\n",
      "LR    RMSE: 3.358646\n",
      "Mean-of-3:  3.174735\n",
      "Saved: submission.csv shape: (113, 4)\n",
      "                                     id  scaled_angle  scaled_depth  \\\n",
      "0  d5cc9ade-6bfd-42d2-8404-99d7506e535c      0.519688      0.494003   \n",
      "1  6fb475ff-1732-42bc-8385-9f80956199fe      0.472408      0.495657   \n",
      "2  39f95c12-deab-4d77-8a9c-feecda4d5a66      0.515327      0.540537   \n",
      "3  5ec65bf7-4892-4076-a572-e01b4b8ff038      0.461818      0.543096   \n",
      "4  52ffbd2a-969c-4e52-af66-c4b4be3c3cbb      0.477521      0.586047   \n",
      "\n",
      "   scaled_left_right  \n",
      "0           0.400136  \n",
      "1           0.568945  \n",
      "2           0.494198  \n",
      "3           0.552921  \n",
      "4           0.399450  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1d6c3",
   "metadata": {
    "papermill": {
     "duration": 0.009653,
     "end_time": "2026-02-21T04:11:46.520216",
     "exception": false,
     "start_time": "2026-02-21T04:11:46.510563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Methodology\n",
    "\n",
    "The complete source code for this submission is publicly available at:  \n",
    "https://github.com/Jormungarr/SPL-UTSPAN-2026-yukuan-s-solution\n",
    "\n",
    "This notebook implements the final pipeline used for my SPL–UTSPAN 2026 submission. The solution models each shot as a fixed-length 3D keypoint sequence and applies structured feature engineering followed by regularized linear regression. The overall design prioritizes robustness, reproducibility, and controlled model complexity.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Representation\n",
    "\n",
    "Each sample consists of 3D keypoints recorded over time. All `*_x`, `*_y`, `*_z` columns are parsed into fixed-length vectors of 240 frames. Every shot is therefore represented as a tensor:\n",
    "\n",
    "$$\n",
    "X \\in \\mathbb{R}^{T \\times F}, \\quad T = 240\n",
    "$$\n",
    "\n",
    "Malformed or missing entries are replaced with zeros to guarantee deterministic behavior and consistent dimensionality.\n",
    "\n",
    "This fixed-length representation enables classical regression models to operate directly on structured temporal data.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Geometric Normalization\n",
    "\n",
    "Raw coordinates contain nuisance variability from camera translation, subject position, and body size differences. To reduce this unwanted variation:\n",
    "\n",
    "1. A root trajectory is estimated (pelvis or mid-hip if available; otherwise a fallback).\n",
    "2. All keypoints are centered relative to this root (translation invariance).\n",
    "3. Sequences are scaled using a robust scale estimate (shoulder width when available, otherwise a median norm).\n",
    "\n",
    "This normalization ensures that the model focuses on relative motion and pose configuration rather than absolute spatial position.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Kinematic and Pose Features\n",
    "\n",
    "From normalized coordinates, additional dynamic features are derived:\n",
    "\n",
    "- **Velocity** (first temporal difference)\n",
    "- **Acceleration** (second temporal difference)\n",
    "\n",
    "These emphasize motion dynamics and highlight transitions near the release event.\n",
    "\n",
    "In addition, a small set of **joint angles** is computed from anatomically meaningful triplets (e.g., shoulder–elbow–wrist). Angles provide a more invariant representation of pose geometry and are particularly informative for predicting shot angle.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Adaptive Release Frame Estimation (t0)\n",
    "\n",
    "A key challenge in sequence modeling is temporal misalignment: the informative release moment varies across shots.\n",
    "\n",
    "To address this, a per-sample release frame \\( t_0 \\) is estimated by detecting the peak of a motion-intensity proxy (velocity magnitude aggregated across features). This heuristic does not require supervision and acts as a lightweight event detector.\n",
    "\n",
    "Aligning features relative to \\( t_0 \\) allows the model to focus on the most predictive temporal neighborhood of the shot.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Multiscale Temporal Summaries\n",
    "\n",
    "The raw tensor $$ X \\in \\mathbb{R}^{T \\times F} $$ is converted into a 2D feature matrix suitable for regression through three components:\n",
    "\n",
    "### (a) Raw Flattened Trajectory\n",
    "\n",
    "The full sequence is vectorized to preserve fine-grained temporal information.\n",
    "\n",
    "### (b) Multiscale Block Statistics\n",
    "\n",
    "For several window sizes (e.g., 6, 12, 24 frames), the sequence is partitioned into blocks. For each block, the mean and standard deviation are computed.\n",
    "\n",
    "This provides coarse temporal structure and reduces sensitivity to frame-level noise. Multiscale pooling improves stability without discarding temporal dynamics.\n",
    "\n",
    "### (c) Local t0-Window Statistics\n",
    "\n",
    "Around the estimated release frame \\( t_0 \\), mean and standard deviation are computed within a symmetric window:\n",
    "\n",
    "\\[\n",
    "[t_0 - w, \\, t_0 + w]\n",
    "\\]\n",
    "\n",
    "Different window widths are used for `angle`, `depth`, and `left_right`, reflecting their different sensitivities to local dynamics.\n",
    "\n",
    "These local summaries capture high-signal information near the release moment.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Optional Angle-Specific Temporal Weighting\n",
    "\n",
    "For the `angle` target only, the notebook includes an optional smooth temporal weighting mechanism (attention-like reweighting). This biases the feature representation toward mid-sequence frames, where release typically occurs.\n",
    "\n",
    "This mechanism is implemented as an ablation toggle and does not introduce additional trainable parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Model Choice: Ridge Regression\n",
    "\n",
    "Three independent models are trained, one for each target:\n",
    "\n",
    "- `angle`\n",
    "- `depth`\n",
    "- `left_right`\n",
    "\n",
    "The final model is **Ridge regression** with **StandardScaler** and **KFold cross-validation**.\n",
    "\n",
    "This choice is motivated by:\n",
    "\n",
    "- Very high-dimensional engineered features\n",
    "- Strong feature collinearity (flattened sequences + pooled statistics)\n",
    "- Desire for stable and reproducible training\n",
    "\n",
    "Ridge regression applies L2 regularization, equivalent to imposing a Gaussian prior on coefficients. This stabilizes the solution, improves conditioning, and reduces variance compared to ordinary least squares.\n",
    "\n",
    "Out-of-fold RMSE is reported for sanity checking.\n",
    "\n",
    "Although tree-based models and residual stacking were explored during experimentation, the final submission prioritizes a regularized linear model for robustness and interpretability.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Submission Generation\n",
    "\n",
    "The notebook reads the official submission template and programmatically matches required column names.\n",
    "\n",
    "If the template expects `scaled_*` columns, predictions are min–max scaled using predefined bounds and clipped to \\([0,1]\\). Otherwise, raw predictions are written directly.\n",
    "\n",
    "This ensures strict compliance with the competition format.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "The final solution combines:\n",
    "\n",
    "- Geometric invariance\n",
    "- Event-based temporal alignment\n",
    "- Multiscale statistical pooling\n",
    "- Regularized linear regression\n",
    "\n",
    "The approach emphasizes structured feature engineering over heavy model complexity, yielding a stable and fully reproducible submission pipeline."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15218621,
     "sourceId": 126310,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 51.550376,
   "end_time": "2026-02-21T04:11:47.146715",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-21T04:10:55.596339",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
