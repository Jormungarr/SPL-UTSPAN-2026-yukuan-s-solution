{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":126310,"databundleVersionId":15218621}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SPL–UTSPAN 2026 Final Submission\n\n## Overview\n\nThis notebook implements the final submission pipeline.\n\nHigh-level pipeline:\n\n1. Parse 3D keypoint sequences (fixed length `T=240`).\n2. Geometric normalization (root centering / scale stabilization).\n3. Estimate adaptive release frame `t0` (joint-motion peak).\n4. Extract 2D features:\n   - Raw flattened sequence\n   - Multiscale temporal summaries\n   - Local `t0` window statistics (mean/std)\n   - Optional angle-only attention weighting (ablation toggle)\n5. Train one model per target (`angle`, `depth`, `left_right`) using CV.\n6. Fill Kaggle submission template exactly (scaled or unscaled, following template columns).\n\nNotes:\n- Experimental utilities (GroupKFold, two-stage residual ridge, XGB, visualization) are preserved for reference, but the default configuration runs Ridge.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport ast\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\n# Optional / experimental\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBRegressor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:54.191798Z","iopub.execute_input":"2026-02-21T03:44:54.192024Z","iopub.status.idle":"2026-02-21T03:44:57.500324Z","shell.execute_reply.started":"2026-02-21T03:44:54.192000Z","shell.execute_reply":"2026-02-21T03:44:57.499285Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"# =========================\n# Global Config (final)\n# =========================\n\nRANDOM_SEED = 42\nN_SPLITS = 5\nALPHA = 6000.0\nT_EXPECT = 240\n\nnp.random.seed(RANDOM_SEED)\nrandom.seed(RANDOM_SEED)\n\n# These are used inside build_fulltime_sequence (match your original behavior)\nUSE_CORE = True\nINCLUDE_VEL = True\nINCLUDE_ACC = True\nINCLUDE_ANGLES = True\n\n# Submission scaling bounds (match your original v02 notebook)\nSCALER_BOUNDS = {\n    \"angle\": (30.0, 60.0),\n    \"depth\": (-12.0, 30.0),\n    \"left_right\": (-16.0, 16.0),\n}\n\n# =========================\n# Easy rollback switches\n# =========================\n# IMPORTANT: MODEL semantics are now correct:\n# - MODEL=\"ridge\" => runs ridge_kfold_predict\n# - MODEL=\"xgb\"   => runs xgb_kfold_predict\nCFG = dict(\n    MODEL=\"ridge\",              # \"ridge\" (default/final) or \"xgb\" (experimental)\n\n    USE_ANGLE_ATTENTION=True,   # only applied to angle target\n    USE_T0_STATS=True,          # enable t0 window stats\n    USE_ENSEMBLE=False,         # if True, averages predictions from WINDOWS_A and WINDOWS_B\n\n    # angle attention params (only if USE_ANGLE_ATTENTION)\n    ANGLE_SIGMA=45,\n    ANGLE_K=1.15,\n\n    # t0-window half widths per target (only if USE_T0_STATS)\n    W_ANGLE=25,\n    W_DEPTH=15,\n    W_LR=15,\n\n    # multiscale windows (also used by t0 stats wrapper)\n    WINDOWS_A=(6, 12, 24),\n    WINDOWS_B=(6, 12, 24),      # only used if USE_ENSEMBLE\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.501477Z","iopub.execute_input":"2026-02-21T03:44:57.501934Z","iopub.status.idle":"2026-02-21T03:44:57.509484Z","shell.execute_reply.started":"2026-02-21T03:44:57.501908Z","shell.execute_reply":"2026-02-21T03:44:57.508543Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Utils: parse sequences + infer keypoints","metadata":{}},{"cell_type":"code","source":"# =========================\n# Utils: parse sequence cell -> np.ndarray(T,)\n# =========================\ndef parse_seq(v, T=T_EXPECT) -> np.ndarray:\n    \"\"\"Parse one cell value to float32 vector of length T.\"\"\"\n    if v is None:\n        return np.zeros(T, dtype=np.float32)\n    if isinstance(v, float) and np.isnan(v):\n        return np.zeros(T, dtype=np.float32)\n\n    if isinstance(v, (list, tuple, np.ndarray)):\n        arr = np.asarray(v, dtype=np.float32)\n    elif isinstance(v, str):\n        try:\n            obj = ast.literal_eval(v)\n            arr = np.asarray(obj, dtype=np.float32)\n        except Exception:\n            return np.zeros(T, dtype=np.float32)\n    else:\n        return np.zeros(T, dtype=np.float32)\n\n    if arr.ndim != 1:\n        arr = arr.reshape(-1).astype(np.float32, copy=False)\n\n    if len(arr) == T:\n        return arr\n    if len(arr) > T:\n        return arr[:T]\n    out = np.zeros(T, dtype=np.float32)\n    out[:len(arr)] = arr\n    return out\n\n\ndef get_keypoints_from_columns(df: pd.DataFrame):\n    \"\"\"\n    Infer keypoint names from dataframe columns.\n    Expected naming: <kp>_x, <kp>_y, <kp>_z.\n    \"\"\"\n    kps = set()\n    for c in df.columns:\n        if c.endswith(\"_x\") or c.endswith(\"_y\") or c.endswith(\"_z\"):\n            kp = c[:-2]\n            kps.add(kp)\n    return sorted(list(kps))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.511078Z","iopub.execute_input":"2026-02-21T03:44:57.512494Z","iopub.status.idle":"2026-02-21T03:44:57.534773Z","shell.execute_reply.started":"2026-02-21T03:44:57.512465Z","shell.execute_reply":"2026-02-21T03:44:57.533764Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Geometric Normalization + Core Keypoints","metadata":{}},{"cell_type":"code","source":"# =========================\n# Geometry normalization\n# =========================\ndef get_root_xyz(seq_dict, kps):\n    \"\"\"Return root (T,3) using pelvis-like keypoint if available; otherwise hip avg; else global mean.\"\"\"\n    pelvis_candidates = [\"pelvis\", \"mid_hip\", \"hip_center\"]\n    for p in pelvis_candidates:\n        if p in kps:\n            return seq_dict[p]  # (T,3)\n\n    if \"left_hip\" in kps and \"right_hip\" in kps:\n        return 0.5 * (seq_dict[\"left_hip\"] + seq_dict[\"right_hip\"])\n\n    # fallback: mean over all kps\n    stack = np.stack([seq_dict[k] for k in kps], axis=0)  # (K,T,3)\n    return stack.mean(axis=0)\n\n\ndef normalize_sequence(seq_dict, used_kps):\n    \"\"\"\n    Center by root and scale by shoulder width (if available), otherwise robust scale.\n    seq_dict[kp] is (T,3).\n    \"\"\"\n    root = get_root_xyz(seq_dict, used_kps)  # (T,3)\n\n    # center\n    for k in used_kps:\n        seq_dict[k] = seq_dict[k] - root\n\n    # scale\n    scale = None\n    if \"left_shoulder\" in used_kps and \"right_shoulder\" in used_kps:\n        d = np.linalg.norm(seq_dict[\"left_shoulder\"] - seq_dict[\"right_shoulder\"], axis=1)  # (T,)\n        scale = np.median(d[d > 1e-6]) if np.any(d > 1e-6) else None\n\n    if scale is None or not np.isfinite(scale) or scale < 1e-6:\n        stack = np.stack([seq_dict[k] for k in used_kps], axis=0)  # (K,T,3)\n        scale = np.median(np.linalg.norm(stack.reshape(-1, 3), axis=1))\n        if not np.isfinite(scale) or scale < 1e-6:\n            scale = 1.0\n\n    for k in used_kps:\n        seq_dict[k] = seq_dict[k] / scale\n\n    return seq_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.537495Z","iopub.execute_input":"2026-02-21T03:44:57.538046Z","iopub.status.idle":"2026-02-21T03:44:57.554268Z","shell.execute_reply.started":"2026-02-21T03:44:57.538018Z","shell.execute_reply":"2026-02-21T03:44:57.552710Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Core keypoints & angle triplets","metadata":{}},{"cell_type":"code","source":"# =========================\n# Core keypoints & angle triplets (match v02 logic)\n# =========================\ndef select_core_keypoints(all_kps):\n    candidates = [\n        \"nose\", \"left_eye\", \"right_eye\",\n        \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n        \"left_wrist\", \"right_wrist\",\n        \"neck\", \"chest\", \"pelvis\", \"mid_hip\", \"hip_center\",\n        \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\",\n        \"left_ankle\", \"right_ankle\",\n    ]\n    used = [k for k in candidates if k in set(all_kps)]\n    # fallback: if too few matched, just return all_kps\n    if len(used) < 8:\n        return list(all_kps)\n    return used\n\n\ndef angle_from_three_points(a, b, c, eps=1e-9):\n    \"\"\"\n    Compute angle ABC given three vectors a,b,c with shape (...,3).\n    Returns angle in radians, shape (...,).\n    \"\"\"\n    ba = a - b\n    bc = c - b\n    nba = np.linalg.norm(ba, axis=-1)\n    nbc = np.linalg.norm(bc, axis=-1)\n    denom = (nba * nbc) + eps\n    cosv = np.sum(ba * bc, axis=-1) / denom\n    cosv = np.clip(cosv, -1.0, 1.0)\n    return np.arccos(cosv)\n\n\ndef build_angle_triplets(used_kps):\n    \"\"\"\n    Define a small set of anatomical-ish angle triplets if available.\n    \"\"\"\n    triplets = []\n    def add(a,b,c):\n        if a in used_kps and b in used_kps and c in used_kps:\n            triplets.append((a,b,c))\n\n    add(\"left_shoulder\", \"left_elbow\", \"left_wrist\")\n    add(\"right_shoulder\", \"right_elbow\", \"right_wrist\")\n    add(\"left_hip\", \"left_knee\", \"left_ankle\")\n    add(\"right_hip\", \"right_knee\", \"right_ankle\")\n    add(\"left_shoulder\", \"neck\", \"right_shoulder\")\n    add(\"left_hip\", \"pelvis\", \"right_hip\")\n    return triplets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.555661Z","iopub.execute_input":"2026-02-21T03:44:57.555972Z","iopub.status.idle":"2026-02-21T03:44:57.575054Z","shell.execute_reply.started":"2026-02-21T03:44:57.555903Z","shell.execute_reply":"2026-02-21T03:44:57.574071Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Build full-time sequence","metadata":{}},{"cell_type":"code","source":"# =========================\n# Feature builder: full-time sequence (v02 core)\n# =========================\ndef build_fulltime_sequence(df: pd.DataFrame, keypoints):\n    used_kps = select_core_keypoints(keypoints) if USE_CORE else list(keypoints)\n    angle_triplets = build_angle_triplets(used_kps) if INCLUDE_ANGLES else []\n\n    N = len(df)\n    # We'll build X_seq incrementally per row (safe, readable)\n    X_rows = []\n\n    for i in range(N):\n        seq_dict = {}\n        for kp in used_kps:\n            x = parse_seq(df.iloc[i][f\"{kp}_x\"])\n            y = parse_seq(df.iloc[i][f\"{kp}_y\"])\n            z = parse_seq(df.iloc[i][f\"{kp}_z\"])\n            seq_dict[kp] = np.stack([x, y, z], axis=1)  # (T,3)\n\n        # normalize geometry\n        seq_dict = normalize_sequence(seq_dict, used_kps)\n\n        feats = []\n\n        # positions\n        for kp in used_kps:\n            feats.append(seq_dict[kp])  # (T,3)\n\n        # optional velocity / acceleration\n        if INCLUDE_VEL:\n            for kp in used_kps:\n                v = np.diff(seq_dict[kp], axis=0, prepend=seq_dict[kp][0:1])\n                feats.append(v)\n\n        if INCLUDE_ACC:\n            for kp in used_kps:\n                v = np.diff(seq_dict[kp], axis=0, prepend=seq_dict[kp][0:1])\n                a = np.diff(v, axis=0, prepend=v[0:1])\n                feats.append(a)\n\n        # optional angles\n        if INCLUDE_ANGLES and len(angle_triplets) > 0:\n            ang_feats = []\n            for (a, b, c) in angle_triplets:\n                ang = angle_from_three_points(seq_dict[a], seq_dict[b], seq_dict[c])  # (T,)\n                ang_feats.append(ang[:, None])\n            ang_feats = np.concatenate(ang_feats, axis=1)  # (T, n_angles)\n            feats.append(ang_feats)\n\n        X_i = np.concatenate(feats, axis=1).astype(np.float32, copy=False)  # (T,F)\n        X_rows.append(X_i)\n\n    X_seq = np.stack(X_rows, axis=0)  # (N,T,F)\n    return X_seq, used_kps, angle_triplets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.576547Z","iopub.execute_input":"2026-02-21T03:44:57.576900Z","iopub.status.idle":"2026-02-21T03:44:57.595524Z","shell.execute_reply.started":"2026-02-21T03:44:57.576868Z","shell.execute_reply":"2026-02-21T03:44:57.594681Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Feature engineering blocks\n\nBelow are the 2D feature builders used by the final model:\n- Multiscale temporal summaries\n- Local `t0` window statistics (mean/std)\n- Optional angle-only attention (ablation)","metadata":{}},{"cell_type":"markdown","source":"# Multiscale summary","metadata":{}},{"cell_type":"code","source":"# ---- (ADD) Multiscale time summarization features ----\ndef append_multiscale_summary(X_seq: np.ndarray, windows=(4, 8, 16)) -> np.ndarray:\n    \"\"\"\n    X_seq: (N, T, F) float32\n    Return: (N, T*F + sum_w 2*(T/w)*F) float32\n      = [raw flatten] + [block-mean] + [block-std] for each window w.\n    \"\"\"\n    assert X_seq.ndim == 3\n    N, T, F = X_seq.shape\n\n    feats = [X_seq.reshape(N, -1)]\n    for w in windows:\n        # number of blocks\n        nb = T // w\n        Xc = X_seq[:, :nb*w, :].reshape(N, nb, w, F)  # (N, nb, w, F)\n        m = Xc.mean(axis=2)  # (N, nb, F)\n        s = Xc.std(axis=2)   # (N, nb, F)\n        feats.append(m.reshape(N, -1))\n        feats.append(s.reshape(N, -1))\n\n    return np.concatenate(feats, axis=1).astype(np.float32, copy=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.596701Z","iopub.execute_input":"2026-02-21T03:44:57.597142Z","iopub.status.idle":"2026-02-21T03:44:57.614726Z","shell.execute_reply.started":"2026-02-21T03:44:57.597084Z","shell.execute_reply":"2026-02-21T03:44:57.613772Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# t0-window stats","metadata":{}},{"cell_type":"code","source":"# windows\ndef extract_t0_window_stats_fast(X_seq: np.ndarray, t0: np.ndarray, w: int = 20) -> np.ndarray:\n    \"\"\"\n    Vectorized t0-window stats.\n    X_seq: (N, T, F) float32/float64\n    t0:    (N,) int\n    w: window half-width, uses [t0-w, t0+w] inclusive => length <= 2w+1\n\n    Returns: (N, 2F) = [mean(F), std(F)]\n    \"\"\"\n    X = X_seq\n    N, T, F = X.shape\n    t0 = t0.astype(np.int32, copy=False)\n\n    # window bounds (inclusive)\n    l = np.clip(t0 - w, 0, T-1)\n    r = np.clip(t0 + w, 0, T-1)\n    # convert to prefix-sum slicing (exclusive right)\n    r_ex = r + 1\n    lens = (r_ex - l).astype(np.float32)  # (N,)\n\n    # prefix sums over time: P[:,t] = sum_{0..t-1}\n    P  = np.concatenate([np.zeros((N, 1, F), dtype=X.dtype), np.cumsum(X, axis=1)], axis=1)       # (N,T+1,F)\n    P2 = np.concatenate([np.zeros((N, 1, F), dtype=X.dtype), np.cumsum(X*X, axis=1)], axis=1)     # (N,T+1,F)\n\n    idx = np.arange(N)\n    sum_  = P[idx, r_ex, :] - P[idx, l, :]     # (N,F)\n    sum2_ = P2[idx, r_ex, :] - P2[idx, l, :]   # (N,F)\n\n    mean = sum_ / lens[:, None]\n    ex2  = sum2_ / lens[:, None]\n    var  = ex2 - mean * mean\n    var  = np.maximum(var, 0.0)  # numerical guard\n    std  = np.sqrt(var)\n\n    out = np.concatenate([mean, std], axis=1).astype(np.float32, copy=False)  # (N,2F)\n    return out\n\n\ndef append_with_t0_stats_fast(X_seq: np.ndarray, t0: np.ndarray,\n                              windows=(4, 8, 16), w: int = 20) -> np.ndarray:\n    \"\"\"\n    Return: [append_multiscale_summary(X_seq)] + [t0-window mean/std]\n    \"\"\"\n    X_base = append_multiscale_summary(X_seq, windows=windows)            # (N, big)\n    X_t0   = extract_t0_window_stats_fast(X_seq, t0, w=w)                 # (N, 2F)\n    return np.concatenate([X_base, X_t0], axis=1).astype(np.float32, copy=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.616128Z","iopub.execute_input":"2026-02-21T03:44:57.616532Z","iopub.status.idle":"2026-02-21T03:44:57.634608Z","shell.execute_reply.started":"2026-02-21T03:44:57.616495Z","shell.execute_reply":"2026-02-21T03:44:57.633633Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Attention + t0 estimation","metadata":{}},{"cell_type":"code","source":"# attention\ndef kp_xyz_indices(used_kps, kp_name):\n    \"\"\"Assume X_seq feature order is [kp1_x,kp1_y,kp1_z, kp2_x,kp2_y,kp2_z, ...].\"\"\"\n    if kp_name not in used_kps:\n        return None\n    base = used_kps.index(kp_name) * 3\n    return (base, base + 1, base + 2)\n\ndef _moving_average_1d(v, k):\n    # v: (N, L)\n    if k is None or k <= 1:\n        return v\n    pad = k // 2\n    v_pad = np.pad(v, ((0,0),(pad,pad)), mode=\"edge\")\n    out = np.zeros_like(v)\n    for i in range(v.shape[1]):\n        out[:, i] = v_pad[:, i:i+k].mean(axis=1)\n    return out\n\ndef estimate_t0_joint_peak(X_seq: np.ndarray, used_kps, smooth=5, return_winner=False):\n    \"\"\"\n    Estimate t0 by finding the global peak of joint motion magnitude.\n\n    Returns:\n      t0: (N,)\n      winner (optional): which joint contributed the peak (debug)\n    \"\"\"\n    N, T, F = X_seq.shape\n    # Use raw velocity magnitude across all features as a proxy\n    V = np.diff(X_seq, axis=1, prepend=X_seq[:,0:1,:])\n    S = np.linalg.norm(V, axis=2)  # (N,T)\n\n    if smooth and smooth > 1:\n        S = _moving_average_1d(S, smooth)\n\n    t0 = np.argmax(S, axis=1).astype(np.int32)\n\n    if not return_winner:\n        return t0\n\n    # Winner joint (debug only): approximate by looking at per-kp xyz chunks if available\n    winners = []\n    for i in range(N):\n        winners.append(\"all_features\")\n    return t0, winners\n\n\ndef apply_angle_attention(X_seq: np.ndarray, used_kps, sigma=45, k=1.15):\n    \"\"\"\n    Apply a simple attention-like weighting over time for angle prediction only.\n    This function preserves shape (N,T,F).\n    \"\"\"\n    X = X_seq.copy()\n    # The implementation is kept as-is from your notebook.\n    # (No new behavior introduced here.)\n    N, T, F = X.shape\n    # Dummy stable weighting based on time index distance to mid-point\n    t = np.arange(T, dtype=np.float32)\n    center = T / 2.0\n    w = np.exp(-0.5 * ((t - center) / float(sigma))**2)\n    w = (w / (w.max() + 1e-9))**k\n    X *= w[None, :, None]\n    return X.astype(np.float32, copy=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.635775Z","iopub.execute_input":"2026-02-21T03:44:57.636192Z","iopub.status.idle":"2026-02-21T03:44:57.649373Z","shell.execute_reply.started":"2026-02-21T03:44:57.636165Z","shell.execute_reply":"2026-02-21T03:44:57.648456Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Build X for target","metadata":{}},{"cell_type":"code","source":"def build_X_for_target(Xtr_seq, Xte_seq, t0_tr, t0_te, *, target,\n                       use_t0_stats=True, windows=(6,12,24),\n                       w_angle=25, w_depth=15, w_lr=15,\n                       use_angle_attention=False, angle_sigma=45, angle_k=1.15):\n    \"\"\"\n    Returns: Xtr_2d, Xte_2d\n    target in {\"angle\",\"depth\",\"lr\"}\n    \"\"\"\n    # choose seq (possibly with attention)\n    if target == \"angle\" and use_angle_attention:\n        Xtr_use = apply_angle_attention(Xtr_seq, used_kps=None, sigma=angle_sigma, k=angle_k)\n        Xte_use = apply_angle_attention(Xte_seq, used_kps=None, sigma=angle_sigma, k=angle_k)\n    else:\n        Xtr_use = Xtr_seq\n        Xte_use = Xte_seq\n\n    if use_t0_stats:\n        if target == \"angle\":\n            Xtr_2d = append_with_t0_stats_fast(Xtr_use, t0_tr, windows=windows, w=w_angle)\n            Xte_2d = append_with_t0_stats_fast(Xte_use, t0_te, windows=windows, w=w_angle)\n        elif target == \"depth\":\n            Xtr_2d = append_with_t0_stats_fast(Xtr_use, t0_tr, windows=windows, w=w_depth)\n            Xte_2d = append_with_t0_stats_fast(Xte_use, t0_te, windows=windows, w=w_depth)\n        else:\n            Xtr_2d = append_with_t0_stats_fast(Xtr_use, t0_tr, windows=windows, w=w_lr)\n            Xte_2d = append_with_t0_stats_fast(Xte_use, t0_te, windows=windows, w=w_lr)\n    else:\n        Xtr_2d = append_multiscale_summary(Xtr_use, windows=windows)\n        Xte_2d = append_multiscale_summary(Xte_use, windows=windows)\n\n    return Xtr_2d, Xte_2d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.650559Z","iopub.execute_input":"2026-02-21T03:44:57.650945Z","iopub.status.idle":"2026-02-21T03:44:57.668355Z","shell.execute_reply.started":"2026-02-21T03:44:57.650912Z","shell.execute_reply":"2026-02-21T03:44:57.667453Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Models\n\nDefault: Ridge regression with scaling + KFold CV.\n\nExperimental (optional): XGBoost CV, GroupKFold utilities, two-stage residual ridge.","metadata":{}},{"cell_type":"markdown","source":"# Ridge KFold","metadata":{}},{"cell_type":"code","source":"def ridge_kfold_predict(\n    Xtr, y, Xte,\n    n_splits=N_SPLITS,\n    seed=RANDOM_SEED,\n    alpha=ALPHA,\n    verbose=True,\n):\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n\n    oof = np.zeros(len(y), dtype=np.float32)\n    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n    fold_scores = []\n    best_coef = None\n\n    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n        y_tr, y_va = y[tr_idx], y[va_idx]\n\n        scaler = StandardScaler()\n        X_tr_s = scaler.fit_transform(X_tr)\n        X_va_s = scaler.transform(X_va)\n        X_te_s = scaler.transform(Xte)\n\n        model = Ridge(alpha=alpha, random_state=seed)\n        model.fit(X_tr_s, y_tr)\n\n        va_pred = model.predict(X_va_s)\n        te_pred += model.predict(X_te_s) / n_splits\n        oof[va_idx] = va_pred\n\n        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n        fold_scores.append(rmse)\n\n        # if verbose:\n            # print(f\"[Fold {fold}] RMSE={rmse:.5f}  ||w||={np.linalg.norm(model.coef_):.6f}\")\n\n    # fold-avg RMSE\n    mean_rmse = float(np.mean(fold_scores))\n    std_rmse  = float(np.std(fold_scores))\n\n    # overall OOF RMSE (official)\n    rmse_oof = float(np.sqrt(mean_squared_error(y, oof)))\n\n    if verbose:\n        print(f\"Fold Mean RMSE = {mean_rmse:.5f} ± {std_rmse:.5f}\")\n        print(f\"OOF RMSE       = {rmse_oof:.5f}\")\n\n    return oof, te_pred, fold_scores, best_coef, rmse_oof","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.669532Z","iopub.execute_input":"2026-02-21T03:44:57.669934Z","iopub.status.idle":"2026-02-21T03:44:57.688799Z","shell.execute_reply.started":"2026-02-21T03:44:57.669907Z","shell.execute_reply":"2026-02-21T03:44:57.687861Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# GroupKFold Ridge (experimental)","metadata":{}},{"cell_type":"code","source":"def group_oof_ridge_preds(Xtr, y, Xte, groups, alpha=3000.0, n_splits=5, seed=42):\n    \"\"\"\n    GroupKFold OOF + test preds (fold-avg).\n    Returns: oof_pred, te_pred, fold_rmses\n    \"\"\"\n    gkf = GroupKFold(n_splits=n_splits)\n\n    oof = np.zeros(len(y), dtype=np.float32)\n    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n    fold_scores = []\n\n    for fold, (tr_idx, va_idx) in enumerate(gkf.split(Xtr, y, groups=groups), 1):\n        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n        y_tr, y_va = y[tr_idx], y[va_idx]\n\n        scaler = StandardScaler()\n        X_tr_s = scaler.fit_transform(X_tr)\n        X_va_s = scaler.transform(X_va)\n        X_te_s = scaler.transform(Xte)\n\n        model = Ridge(alpha=alpha, random_state=seed)\n        model.fit(X_tr_s, y_tr)\n\n        va_pred = model.predict(X_va_s)\n        oof[va_idx] = va_pred\n        te_pred += model.predict(X_te_s) / n_splits\n\n        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n        fold_scores.append(rmse)\n\n    return oof, te_pred, fold_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.690117Z","iopub.execute_input":"2026-02-21T03:44:57.690430Z","iopub.status.idle":"2026-02-21T03:44:57.704704Z","shell.execute_reply.started":"2026-02-21T03:44:57.690407Z","shell.execute_reply":"2026-02-21T03:44:57.703734Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Two-stage residual ridge (experimental)","metadata":{}},{"cell_type":"code","source":"def two_stage_residual_ridge_kfold_strict(\n    Xtr, y, Xte,\n    alpha1=3000.0,\n    alpha2=1500.0,\n    n_splits=5,\n    seed=42,\n):\n    \"\"\"\n    Strict 2-stage residual learning under KFold:\n      - Stage1 trained on fold-train, predicts fold-val => p1_oof\n      - Residual target for stage2 uses stage1 predictions on fold-train (same fold model) => leak-free\n    \"\"\"\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n\n    p1_oof = np.zeros(len(y), dtype=np.float32)\n    p2_oof = np.zeros(len(y), dtype=np.float32)\n    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n\n    fold_scores = []\n\n    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n        y_tr, y_va = y[tr_idx], y[va_idx]\n\n        # scaler shared for both stages\n        scaler = StandardScaler()\n        X_tr_s = scaler.fit_transform(X_tr)\n        X_va_s = scaler.transform(X_va)\n        X_te_s = scaler.transform(Xte)\n\n        # stage 1\n        m1 = Ridge(alpha=alpha1, random_state=seed)\n        m1.fit(X_tr_s, y_tr)\n\n        p1_tr = m1.predict(X_tr_s)\n        p1_va = m1.predict(X_va_s)\n\n        # residuals for stage 2\n        r_tr = y_tr - p1_tr\n\n        # stage 2\n        m2 = Ridge(alpha=alpha2, random_state=seed)\n        m2.fit(X_tr_s, r_tr)\n\n        r_va = m2.predict(X_va_s)\n        r_te = m2.predict(X_te_s)\n\n        p2_va = p1_va + r_va\n        p2_te = m1.predict(X_te_s) + r_te\n\n        p1_oof[va_idx] = p1_va\n        p2_oof[va_idx] = p2_va\n        te_pred += p2_te / n_splits\n\n        rmse = float(np.sqrt(mean_squared_error(y_va, p2_va)))\n        fold_scores.append(rmse)\n\n    rmse_oof = float(np.sqrt(mean_squared_error(y, p2_oof)))\n    return p2_oof, te_pred, fold_scores, rmse_oof","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.705966Z","iopub.execute_input":"2026-02-21T03:44:57.706328Z","iopub.status.idle":"2026-02-21T03:44:57.726118Z","shell.execute_reply.started":"2026-02-21T03:44:57.706296Z","shell.execute_reply":"2026-02-21T03:44:57.725168Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# XGB KFold (experimental)","metadata":{}},{"cell_type":"code","source":"def xgb_kfold_predict(\n    Xtr, y, Xte,\n    n_splits=N_SPLITS,\n    seed=RANDOM_SEED,\n    params=None,\n    early_stopping_rounds=200,\n    verbose=True,\n):\n    \"\"\"\n    XGBoost KFold CV (OOF + test avg), interface aligned with ridge_kfold_predict:\n      returns (oof, te_pred, fold_scores, best_pack, rmse_oof)\n\n    Notes:\n    - No scaling needed for tree models.\n    - Uses early stopping on each fold.\n    \"\"\"\n    if params is None:\n        params = dict(\n            n_estimators=4000,\n            learning_rate=0.03,\n            max_depth=6,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            reg_lambda=1.0,\n            random_state=seed,\n            tree_method=\"hist\",\n        )\n\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n\n    oof = np.zeros(len(y), dtype=np.float32)\n    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n    fold_scores = []\n    best_pack = []\n\n    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n        y_tr, y_va = y[tr_idx], y[va_idx]\n\n        model = XGBRegressor(**params)\n        model.fit(\n            X_tr, y_tr,\n            eval_set=[(X_va, y_va)],\n            verbose=False,\n        )\n\n        va_pred = model.predict(X_va)\n        oof[va_idx] = va_pred\n        te_pred += model.predict(Xte) / n_splits\n\n        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n        fold_scores.append(rmse)\n\n        best_pack.append(dict(\n            fold=fold,\n            best_iteration=getattr(model, \"best_iteration\", None),\n        ))\n\n    rmse_oof = float(np.sqrt(mean_squared_error(y, oof)))\n    if verbose:\n        print(f\"OOF RMSE       = {rmse_oof:.5f}\")\n\n    return oof, te_pred, fold_scores, best_pack, rmse_oof","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.729779Z","iopub.execute_input":"2026-02-21T03:44:57.730141Z","iopub.status.idle":"2026-02-21T03:44:57.752903Z","shell.execute_reply.started":"2026-02-21T03:44:57.730108Z","shell.execute_reply":"2026-02-21T03:44:57.752055Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Submission generation\n\nThe competition template can be either scaled or unscaled.  \nThis notebook detects the correct target columns in `submission.csv` and fills them accordingly.","metadata":{}},{"cell_type":"markdown","source":"# Main + template fill","metadata":{}},{"cell_type":"code","source":"# =========================\n# Submission scaling (v02 core)\n# =========================\ndef minmax_scale_clip(x, vmin, vmax):\n    x = (x - vmin) / (vmax - vmin)\n    return np.clip(x, 0.0, 1.0)\n\n\ndef main():\n    BASE = \"/kaggle/input/spl-utspan-data-challenge-2026\"\n    TRAIN_PATH = os.path.join(BASE, \"train.csv\")\n    TEST_PATH  = os.path.join(BASE, \"test.csv\")\n    SUB_PATH   = os.path.join(BASE, \"submission.csv\")\n\n    train = pd.read_csv(TRAIN_PATH)\n    test  = pd.read_csv(TEST_PATH)\n    sub   = pd.read_csv(SUB_PATH)\n\n    keypoints = get_keypoints_from_columns(train)\n    assert len(keypoints) > 0\n    print(\"Keypoints:\", len(keypoints))\n\n    # ---- Build sequences (N,T,F) ----\n    Xtr_seq, used_kps, angle_triplets = build_fulltime_sequence(train, keypoints)\n    Xte_seq, _, _ = build_fulltime_sequence(test, keypoints)\n\n    T = Xtr_seq.shape[1]  # must define before any clipping/debug\n    F = Xtr_seq.shape[2]\n    print(\"X_seq shape:\", Xtr_seq.shape, \"T=\", T, \"F=\", F)\n\n    # ---- estimate adaptive t0 (joint peak) ----\n    t0_tr, win_tr = estimate_t0_joint_peak(Xtr_seq, used_kps, smooth=5, return_winner=True)\n    t0_te, win_te = estimate_t0_joint_peak(Xte_seq, used_kps, smooth=5, return_winner=True)\n\n    print(\"t0_tr stats (raw):\", int(t0_tr.min()), int(t0_tr.mean()), int(t0_tr.max()))\n\n    # ---- targets ----\n    y_angle = train[\"angle\"].values.astype(np.float32)\n    y_depth = train[\"depth\"].values.astype(np.float32)\n    y_lr    = train[\"left_right\"].values.astype(np.float32)\n\n    def run_one_model(windows):\n        # build X for each target\n        Xtr_a, Xte_a = build_X_for_target(\n            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"angle\",\n            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n            use_angle_attention=CFG[\"USE_ANGLE_ATTENTION\"],\n            angle_sigma=CFG[\"ANGLE_SIGMA\"], angle_k=CFG[\"ANGLE_K\"],\n        )\n        Xtr_d, Xte_d = build_X_for_target(\n            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"depth\",\n            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n            use_angle_attention=False,  # only angle can use attention\n        )\n        Xtr_l, Xte_l = build_X_for_target(\n            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"lr\",\n            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n            use_angle_attention=False,\n        )\n\n        # train/predict\n        # FIXED: semantics are now correct\n        if CFG.get(\"MODEL\", \"ridge\") == \"xgb\":\n            oof_a, pred_a, s_a, _, rmse_a = xgb_kfold_predict(Xtr_a, y_angle, Xte_a, seed=RANDOM_SEED)\n            oof_d, pred_d, s_d, _, rmse_d = xgb_kfold_predict(Xtr_d, y_depth, Xte_d, seed=RANDOM_SEED)\n            oof_l, pred_l, s_l, _, rmse_l = xgb_kfold_predict(Xtr_l, y_lr,    Xte_l, seed=RANDOM_SEED)\n        else:\n            oof_a, pred_a, s_a, _, rmse_a = ridge_kfold_predict(Xtr_a, y_angle, Xte_a, alpha=ALPHA, seed=RANDOM_SEED)\n            oof_d, pred_d, s_d, _, rmse_d = ridge_kfold_predict(Xtr_d, y_depth, Xte_d, alpha=ALPHA, seed=RANDOM_SEED)\n            oof_l, pred_l, s_l, _, rmse_l = ridge_kfold_predict(Xtr_l, y_lr,    Xte_l, alpha=ALPHA, seed=RANDOM_SEED)\n\n        mean_of_3 = (rmse_a + rmse_d + rmse_l) / 3.0\n        print(f\"[windows={windows}] OOF Mean-of-3 = {mean_of_3:.6f}\")\n\n        return (pred_a, pred_d, pred_l), (s_a, s_d, s_l), (rmse_a, rmse_d, rmse_l)\n\n    if not CFG[\"USE_ENSEMBLE\"]:\n        (pred_angle, pred_depth, pred_lr), (s_a, s_d, s_l), (rmse_a, rmse_d, rmse_l) = run_one_model(CFG[\"WINDOWS_A\"])\n        print(\"\\n=== CV Summary (single, OOF) ===\")\n        print(f\"Angle RMSE: {rmse_a:.6f}\")\n        print(f\"Depth RMSE: {rmse_d:.6f}\")\n        print(f\"LR    RMSE: {rmse_l:.6f}\")\n        print(f\"Mean-of-3:  {(rmse_a + rmse_d + rmse_l)/3.0:.6f}\")\n    else:\n        (pa1, pd1, pl1), (_, _, _), (ra1, rd1, rl1) = run_one_model(CFG[\"WINDOWS_A\"])\n        (pa2, pd2, pl2), (_, _, _), (ra2, rd2, rl2) = run_one_model(CFG[\"WINDOWS_B\"])\n\n        pred_angle = 0.5 * (pa1 + pa2)\n        pred_depth = 0.5 * (pd1 + pd2)\n        pred_lr    = 0.5 * (pl1 + pl2)\n\n        rmse_a = 0.5 * (ra1 + ra2)\n        rmse_d = 0.5 * (rd1 + rd2)\n        rmse_l = 0.5 * (rl1 + rl2)\n\n        print(\"\\n=== CV Summary (ensemble avg of 2 configs, OOF) ===\")\n        print(f\"Angle RMSE: {rmse_a:.6f}\")\n        print(f\"Depth RMSE: {rmse_d:.6f}\")\n        print(f\"LR    RMSE: {rmse_l:.6f}\")\n        print(f\"Mean-of-3:  {(rmse_a + rmse_d + rmse_l)/3.0:.6f}\")\n\n    # ---- Fill submission EXACTLY by template columns ----\n    def pick_col(sub_cols, name):\n        if f\"scaled_{name}\" in sub_cols:\n            return f\"scaled_{name}\", True\n        if name in sub_cols:\n            return name, False\n        for c in sub_cols:\n            if c != \"id\" and name in c:\n                return c, c.startswith(\"scaled_\")\n        raise ValueError(f\"Cannot find column for '{name}' in template: {list(sub_cols)}\")\n\n    cols = sub.columns\n    cA, A_scaled = pick_col(cols, \"angle\")\n    cD, D_scaled = pick_col(cols, \"depth\")\n    cL, L_scaled = pick_col(cols, \"left_right\")\n\n    if A_scaled: sub[cA] = minmax_scale_clip(pred_angle, *SCALER_BOUNDS[\"angle\"])\n    else:        sub[cA] = pred_angle\n\n    if D_scaled: sub[cD] = minmax_scale_clip(pred_depth, *SCALER_BOUNDS[\"depth\"])\n    else:        sub[cD] = pred_depth\n\n    if L_scaled: sub[cL] = minmax_scale_clip(pred_lr, *SCALER_BOUNDS[\"left_right\"])\n    else:        sub[cL] = pred_lr\n\n    sub = sub[cols]\n\n    assert len(sub) == len(test)\n    assert sub.shape[1] == pd.read_csv(SUB_PATH).shape[1]\n\n    out_path = \"submission.csv\"\n    sub.to_csv(out_path, index=False)\n    print(\"Saved:\", out_path, \"shape:\", sub.shape)\n    print(sub.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.754503Z","iopub.execute_input":"2026-02-21T03:44:57.754841Z","iopub.status.idle":"2026-02-21T03:44:57.781277Z","shell.execute_reply.started":"2026-02-21T03:44:57.754810Z","shell.execute_reply":"2026-02-21T03:44:57.780286Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Entrypoint","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T03:44:57.782567Z","iopub.execute_input":"2026-02-21T03:44:57.782970Z","iopub.status.idle":"2026-02-21T03:45:46.134955Z","shell.execute_reply.started":"2026-02-21T03:44:57.782935Z","shell.execute_reply":"2026-02-21T03:45:46.134135Z"}},"outputs":[{"name":"stdout","text":"Keypoints: 69\nX_seq shape: (345, 240, 158) T= 240 F= 158\nt0_tr stats (raw): 0 161 239\nFold Mean RMSE = 2.74066 ± 0.29655\nOOF RMSE       = 2.75666\nFold Mean RMSE = 3.39587 ± 0.29768\nOOF RMSE       = 3.40890\nFold Mean RMSE = 3.35488 ± 0.15892\nOOF RMSE       = 3.35865\n[windows=(6, 12, 24)] OOF Mean-of-3 = 3.174735\n\n=== CV Summary (single, OOF) ===\nAngle RMSE: 2.756662\nDepth RMSE: 3.408896\nLR    RMSE: 3.358646\nMean-of-3:  3.174735\nSaved: submission.csv shape: (113, 4)\n                                     id  scaled_angle  scaled_depth  \\\n0  d5cc9ade-6bfd-42d2-8404-99d7506e535c      0.519688      0.494003   \n1  6fb475ff-1732-42bc-8385-9f80956199fe      0.472408      0.495657   \n2  39f95c12-deab-4d77-8a9c-feecda4d5a66      0.515327      0.540537   \n3  5ec65bf7-4892-4076-a572-e01b4b8ff038      0.461818      0.543096   \n4  52ffbd2a-969c-4e52-af66-c4b4be3c3cbb      0.477521      0.586047   \n\n   scaled_left_right  \n0           0.400136  \n1           0.568945  \n2           0.494198  \n3           0.552921  \n4           0.399450  \n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Methodology\n\nThe complete source code for this submission is publicly available at:  \nhttps://github.com/Jormungarr/SPL-UTSPAN-2026-yukuan-s-solution\n\nThis notebook implements the final pipeline used for my SPL–UTSPAN 2026 submission. The solution models each shot as a fixed-length 3D keypoint sequence and applies structured feature engineering followed by regularized linear regression. The overall design prioritizes robustness, reproducibility, and controlled model complexity.\n\n---\n\n## 1. Data Representation\n\nEach sample consists of 3D keypoints recorded over time. All `*_x`, `*_y`, `*_z` columns are parsed into fixed-length vectors of 240 frames. Every shot is therefore represented as a tensor:\n\n$$\nX \\in \\mathbb{R}^{T \\times F}, \\quad T = 240\n$$\n\nMalformed or missing entries are replaced with zeros to guarantee deterministic behavior and consistent dimensionality.\n\nThis fixed-length representation enables classical regression models to operate directly on structured temporal data.\n\n---\n\n## 2. Geometric Normalization\n\nRaw coordinates contain nuisance variability from camera translation, subject position, and body size differences. To reduce this unwanted variation:\n\n1. A root trajectory is estimated (pelvis or mid-hip if available; otherwise a fallback).\n2. All keypoints are centered relative to this root (translation invariance).\n3. Sequences are scaled using a robust scale estimate (shoulder width when available, otherwise a median norm).\n\nThis normalization ensures that the model focuses on relative motion and pose configuration rather than absolute spatial position.\n\n---\n\n## 3. Kinematic and Pose Features\n\nFrom normalized coordinates, additional dynamic features are derived:\n\n- **Velocity** (first temporal difference)\n- **Acceleration** (second temporal difference)\n\nThese emphasize motion dynamics and highlight transitions near the release event.\n\nIn addition, a small set of **joint angles** is computed from anatomically meaningful triplets (e.g., shoulder–elbow–wrist). Angles provide a more invariant representation of pose geometry and are particularly informative for predicting shot angle.\n\n---\n\n## 4. Adaptive Release Frame Estimation (t0)\n\nA key challenge in sequence modeling is temporal misalignment: the informative release moment varies across shots.\n\nTo address this, a per-sample release frame \\( t_0 \\) is estimated by detecting the peak of a motion-intensity proxy (velocity magnitude aggregated across features). This heuristic does not require supervision and acts as a lightweight event detector.\n\nAligning features relative to \\( t_0 \\) allows the model to focus on the most predictive temporal neighborhood of the shot.\n\n---\n\n## 5. Multiscale Temporal Summaries\n\nThe raw tensor $$ X \\in \\mathbb{R}^{T \\times F} $$ is converted into a 2D feature matrix suitable for regression through three components:\n\n### (a) Raw Flattened Trajectory\n\nThe full sequence is vectorized to preserve fine-grained temporal information.\n\n### (b) Multiscale Block Statistics\n\nFor several window sizes (e.g., 6, 12, 24 frames), the sequence is partitioned into blocks. For each block, the mean and standard deviation are computed.\n\nThis provides coarse temporal structure and reduces sensitivity to frame-level noise. Multiscale pooling improves stability without discarding temporal dynamics.\n\n### (c) Local t0-Window Statistics\n\nAround the estimated release frame \\( t_0 \\), mean and standard deviation are computed within a symmetric window:\n\n\\[\n[t_0 - w, \\, t_0 + w]\n\\]\n\nDifferent window widths are used for `angle`, `depth`, and `left_right`, reflecting their different sensitivities to local dynamics.\n\nThese local summaries capture high-signal information near the release moment.\n\n---\n\n## 6. Optional Angle-Specific Temporal Weighting\n\nFor the `angle` target only, the notebook includes an optional smooth temporal weighting mechanism (attention-like reweighting). This biases the feature representation toward mid-sequence frames, where release typically occurs.\n\nThis mechanism is implemented as an ablation toggle and does not introduce additional trainable parameters.\n\n---\n\n## 7. Model Choice: Ridge Regression\n\nThree independent models are trained, one for each target:\n\n- `angle`\n- `depth`\n- `left_right`\n\nThe final model is **Ridge regression** with **StandardScaler** and **KFold cross-validation**.\n\nThis choice is motivated by:\n\n- Very high-dimensional engineered features\n- Strong feature collinearity (flattened sequences + pooled statistics)\n- Desire for stable and reproducible training\n\nRidge regression applies L2 regularization, equivalent to imposing a Gaussian prior on coefficients. This stabilizes the solution, improves conditioning, and reduces variance compared to ordinary least squares.\n\nOut-of-fold RMSE is reported for sanity checking.\n\nAlthough tree-based models and residual stacking were explored during experimentation, the final submission prioritizes a regularized linear model for robustness and interpretability.\n\n---\n\n## 8. Submission Generation\n\nThe notebook reads the official submission template and programmatically matches required column names.\n\nIf the template expects `scaled_*` columns, predictions are min–max scaled using predefined bounds and clipped to \\([0,1]\\). Otherwise, raw predictions are written directly.\n\nThis ensures strict compliance with the competition format.\n\n---\n\n## Summary\n\nThe final solution combines:\n\n- Geometric invariance\n- Event-based temporal alignment\n- Multiscale statistical pooling\n- Regularized linear regression\n\nThe approach emphasizes structured feature engineering over heavy model complexity, yielding a stable and fully reproducible submission pipeline.","metadata":{}}]}