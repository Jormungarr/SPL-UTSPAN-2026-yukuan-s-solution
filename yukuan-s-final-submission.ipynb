{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7107fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:14.192407Z",
     "iopub.status.busy": "2026-02-21T02:59:14.191982Z",
     "iopub.status.idle": "2026-02-21T02:59:16.248716Z",
     "shell.execute_reply": "2026-02-21T02:59:16.247947Z"
    },
    "papermill": {
     "duration": 2.064622,
     "end_time": "2026-02-21T02:59:16.250408",
     "exception": false,
     "start_time": "2026-02-21T02:59:14.185786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# v02_minimal.py\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7719e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.258772Z",
     "iopub.status.busy": "2026-02-21T02:59:16.258150Z",
     "iopub.status.idle": "2026-02-21T02:59:16.262355Z",
     "shell.execute_reply": "2026-02-21T02:59:16.261695Z"
    },
    "papermill": {
     "duration": 0.009641,
     "end_time": "2026-02-21T02:59:16.263611",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.253970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Config (match v02)\n",
    "# =========================\n",
    "RANDOM_SEED = 42\n",
    "N_SPLITS = 5\n",
    "ALPHA = 6000.0\n",
    "T_EXPECT = 240\n",
    "\n",
    "USE_CORE = True\n",
    "INCLUDE_VEL = True\n",
    "INCLUDE_ACC = True\n",
    "INCLUDE_ANGLES = True\n",
    "\n",
    "# Submission scaling bounds (match your v02 notebook)\n",
    "SCALER_BOUNDS = {\n",
    "    \"angle\": (30.0, 60.0),\n",
    "    \"depth\": (-12.0, 30.0),\n",
    "    \"left_right\": (-16.0, 16.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6983c124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.271134Z",
     "iopub.status.busy": "2026-02-21T02:59:16.270554Z",
     "iopub.status.idle": "2026-02-21T02:59:16.278360Z",
     "shell.execute_reply": "2026-02-21T02:59:16.277849Z"
    },
    "papermill": {
     "duration": 0.012877,
     "end_time": "2026-02-21T02:59:16.279621",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.266744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Utils: parse sequence cell -> np.ndarray(T,)\n",
    "# =========================\n",
    "def parse_seq(v, T=T_EXPECT) -> np.ndarray:\n",
    "    \"\"\"Parse one cell value to float32 vector of length T.\"\"\"\n",
    "    if v is None:\n",
    "        return np.zeros(T, dtype=np.float32)\n",
    "    if isinstance(v, float) and np.isnan(v):\n",
    "        return np.zeros(T, dtype=np.float32)\n",
    "\n",
    "    if isinstance(v, (list, tuple, np.ndarray)):\n",
    "        arr = np.asarray(v, dtype=np.float32).reshape(-1)\n",
    "    elif isinstance(v, str):\n",
    "        s = v.strip()\n",
    "        if s == \"\":\n",
    "            return np.zeros(T, dtype=np.float32)\n",
    "        try:\n",
    "            arr = np.asarray(ast.literal_eval(s), dtype=np.float32).reshape(-1)\n",
    "        except Exception:\n",
    "            return np.zeros(T, dtype=np.float32)\n",
    "    else:\n",
    "        # unknown type -> safest fallback\n",
    "        return np.zeros(T, dtype=np.float32)\n",
    "\n",
    "    if arr.size >= T:\n",
    "        return arr[:T].astype(np.float32, copy=False)\n",
    "    out = np.zeros(T, dtype=np.float32)\n",
    "    out[: arr.size] = arr\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_keypoints_from_columns(df: pd.DataFrame):\n",
    "    \"\"\"Infer keypoints by detecting *_x, *_y, *_z triplets.\"\"\"\n",
    "    cols = set(df.columns)\n",
    "    kps = []\n",
    "    for c in df.columns:\n",
    "        if c.endswith(\"_x\"):\n",
    "            base = c[:-2]\n",
    "            if (base + \"_y\") in cols and (base + \"_z\") in cols:\n",
    "                kps.append(base)\n",
    "    return sorted(kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b599a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.287074Z",
     "iopub.status.busy": "2026-02-21T02:59:16.286881Z",
     "iopub.status.idle": "2026-02-21T02:59:16.295186Z",
     "shell.execute_reply": "2026-02-21T02:59:16.294666Z"
    },
    "papermill": {
     "duration": 0.013591,
     "end_time": "2026-02-21T02:59:16.296444",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.282853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Geometry normalization\n",
    "# =========================\n",
    "def get_root_xyz(seq_dict, kps):\n",
    "    \"\"\"Return root (T,3) using pelvis-like keypoint if available; otherwise hip avg; else global mean.\"\"\"\n",
    "    pelvis_candidates = [\"pelvis\", \"mid_hip\", \"hip_center\"]\n",
    "    for p in pelvis_candidates:\n",
    "        if p in kps:\n",
    "            return seq_dict[p]  # (T,3)\n",
    "\n",
    "    if \"left_hip\" in kps and \"right_hip\" in kps:\n",
    "        return 0.5 * (seq_dict[\"left_hip\"] + seq_dict[\"right_hip\"])\n",
    "\n",
    "    # fallback: mean over all keypoints\n",
    "    stack = np.stack([seq_dict[k] for k in kps], axis=0)  # (K,T,3)\n",
    "    return stack.mean(axis=0)  # (T,3)\n",
    "\n",
    "\n",
    "def get_scale(seq_dict, kps, root_xyz):\n",
    "    \"\"\"Return scale (T,1) using shoulder/hip width if possible; else median distance to root.\"\"\"\n",
    "    eps = 1e-6\n",
    "\n",
    "    def safe_norm(x):\n",
    "        return np.sqrt((x * x).sum(axis=-1, keepdims=True))  # (T,1)\n",
    "\n",
    "    if \"left_shoulder\" in kps and \"right_shoulder\" in kps:\n",
    "        w = safe_norm(seq_dict[\"left_shoulder\"] - seq_dict[\"right_shoulder\"])\n",
    "        return np.clip(w, eps, None)\n",
    "\n",
    "    if \"left_hip\" in kps and \"right_hip\" in kps:\n",
    "        w = safe_norm(seq_dict[\"left_hip\"] - seq_dict[\"right_hip\"])\n",
    "        return np.clip(w, eps, None)\n",
    "\n",
    "    # fallback: median distance to root across keypoints\n",
    "    dists = []\n",
    "    for k in kps:\n",
    "        d = safe_norm(seq_dict[k] - root_xyz)  # (T,1)\n",
    "        dists.append(d)\n",
    "    D = np.concatenate(dists, axis=1)  # (T,K)\n",
    "    med = np.median(D, axis=1, keepdims=True)  # (T,1)\n",
    "    return np.clip(med, eps, None)\n",
    "\n",
    "\n",
    "def diff1(x):\n",
    "    \"\"\"First difference along time, keeping same length.\"\"\"\n",
    "    # x: (T,F)\n",
    "    out = np.empty_like(x)\n",
    "    out[0] = x[0]\n",
    "    out[1:] = x[1:] - x[:-1]\n",
    "    return out\n",
    "\n",
    "\n",
    "def diff2(x):\n",
    "    return diff1(diff1(x))\n",
    "\n",
    "\n",
    "def angle_3pts(a, b, c):\n",
    "    \"\"\"\n",
    "    Angle ABC per frame in radians.\n",
    "    a,b,c: (T,3)\n",
    "    returns: (T,1)\n",
    "    \"\"\"\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    ba_n = np.linalg.norm(ba, axis=1, keepdims=True) + 1e-6\n",
    "    bc_n = np.linalg.norm(bc, axis=1, keepdims=True) + 1e-6\n",
    "    cos = (ba * bc).sum(axis=1, keepdims=True) / (ba_n * bc_n)\n",
    "    cos = np.clip(cos, -1.0, 1.0)\n",
    "    return np.arccos(cos).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b496010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.303850Z",
     "iopub.status.busy": "2026-02-21T02:59:16.303389Z",
     "iopub.status.idle": "2026-02-21T02:59:16.308600Z",
     "shell.execute_reply": "2026-02-21T02:59:16.308080Z"
    },
    "papermill": {
     "duration": 0.010315,
     "end_time": "2026-02-21T02:59:16.309879",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.299564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Core keypoints & angle triplets (match v02 logic)\n",
    "# =========================\n",
    "def select_core_keypoints(all_kps):\n",
    "    candidates = [\n",
    "        \"nose\", \"left_eye\", \"right_eye\",\n",
    "        \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n",
    "        \"left_wrist\", \"right_wrist\",\n",
    "        \"neck\", \"chest\", \"pelvis\", \"mid_hip\", \"hip_center\",\n",
    "        \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\",\n",
    "        \"left_ankle\", \"right_ankle\",\n",
    "    ]\n",
    "    core = [k for k in candidates if k in all_kps]\n",
    "    if len(core) < 6:\n",
    "        return list(all_kps)\n",
    "    return core\n",
    "\n",
    "\n",
    "def build_angle_triplets(used_kps):\n",
    "    # Try common triplets; only keep if all three exist\n",
    "    triplets = [\n",
    "        (\"left_shoulder\", \"left_elbow\", \"left_wrist\"),\n",
    "        (\"right_shoulder\", \"right_elbow\", \"right_wrist\"),\n",
    "        (\"left_hip\", \"left_knee\", \"left_ankle\"),\n",
    "        (\"right_hip\", \"right_knee\", \"right_ankle\"),\n",
    "        (\"left_hip\", \"pelvis\", \"right_hip\"),\n",
    "        (\"left_shoulder\", \"chest\", \"right_shoulder\"),\n",
    "    ]\n",
    "    out = []\n",
    "    s = set(used_kps)\n",
    "    for a, b, c in triplets:\n",
    "        if a in s and b in s and c in s:\n",
    "            out.append((a, b, c))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c244f6b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.317340Z",
     "iopub.status.busy": "2026-02-21T02:59:16.316967Z",
     "iopub.status.idle": "2026-02-21T02:59:16.324081Z",
     "shell.execute_reply": "2026-02-21T02:59:16.323521Z"
    },
    "papermill": {
     "duration": 0.012245,
     "end_time": "2026-02-21T02:59:16.325280",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.313035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Feature builder: full-time sequence (v02 core)\n",
    "# =========================\n",
    "def build_fulltime_sequence(df: pd.DataFrame, keypoints):\n",
    "    used_kps = select_core_keypoints(keypoints) if USE_CORE else list(keypoints)\n",
    "    angle_triplets = build_angle_triplets(used_kps) if INCLUDE_ANGLES else []\n",
    "\n",
    "    N = len(df)\n",
    "    # We'll build X_seq incrementally per row (safe, readable)\n",
    "    X_list = []\n",
    "\n",
    "    for i in range(N):\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        # gather raw sequences\n",
    "        seq_dict = {}\n",
    "        for kp in used_kps:\n",
    "            x = parse_seq(row[f\"{kp}_x\"])\n",
    "            y = parse_seq(row[f\"{kp}_y\"])\n",
    "            z = parse_seq(row[f\"{kp}_z\"])\n",
    "            seq_dict[kp] = np.stack([x, y, z], axis=1)  # (T,3)\n",
    "\n",
    "        root = get_root_xyz(seq_dict, used_kps)         # (T,3)\n",
    "        scale = get_scale(seq_dict, used_kps, root)     # (T,1)\n",
    "\n",
    "        # normalize per frame\n",
    "        for kp in used_kps:\n",
    "            seq_dict[kp] = (seq_dict[kp] - root) / scale\n",
    "\n",
    "        # pos: (T, 3K)\n",
    "        pos = np.concatenate([seq_dict[kp] for kp in used_kps], axis=1).astype(np.float32)\n",
    "\n",
    "        feats = [pos]\n",
    "        if INCLUDE_VEL:\n",
    "            feats.append(diff1(pos))\n",
    "        if INCLUDE_ACC:\n",
    "            feats.append(diff2(pos))\n",
    "        if INCLUDE_ANGLES and len(angle_triplets) > 0:\n",
    "            angs = []\n",
    "            for a, b, c in angle_triplets:\n",
    "                angs.append(angle_3pts(seq_dict[a], seq_dict[b], seq_dict[c]))  # (T,1)\n",
    "            feats.append(np.concatenate(angs, axis=1))  # (T,n_ang)\n",
    "\n",
    "        Xi = np.concatenate(feats, axis=1).astype(np.float32)  # (T,F)\n",
    "        X_list.append(Xi)\n",
    "\n",
    "    X_seq = np.stack(X_list, axis=0)  # (N,T,F)\n",
    "    return X_seq, used_kps, angle_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0147f809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.332700Z",
     "iopub.status.busy": "2026-02-21T02:59:16.332293Z",
     "iopub.status.idle": "2026-02-21T02:59:16.338506Z",
     "shell.execute_reply": "2026-02-21T02:59:16.337974Z"
    },
    "papermill": {
     "duration": 0.011484,
     "end_time": "2026-02-21T02:59:16.339889",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.328405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def group_oof_ridge_preds(Xtr, y, Xte, groups, alpha=3000.0, n_splits=5, seed=42):\n",
    "    \"\"\"\n",
    "    GroupKFold OOF + test preds (fold-avg).\n",
    "    Returns: oof_pred, te_pred, fold_rmses\n",
    "    \"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_sum = np.zeros(Xte.shape[0], dtype=np.float64)\n",
    "    fold_rmses = []\n",
    "\n",
    "    # GroupKFold 不用 seed/shuffle；如果你想 shuffle，需要自己打乱 group 顺序（可先不搞）\n",
    "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(Xtr, y, groups=groups), 1):\n",
    "        scaler = StandardScaler()\n",
    "        Xtr_s = scaler.fit_transform(Xtr[tr_idx])\n",
    "        Xva_s = scaler.transform(Xtr[va_idx])\n",
    "        Xte_s = scaler.transform(Xte)\n",
    "\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(Xtr_s, y[tr_idx])\n",
    "\n",
    "        oof[va_idx] = model.predict(Xva_s).astype(np.float32)\n",
    "        te_sum += model.predict(Xte_s).astype(np.float64)\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y[va_idx], oof[va_idx])))\n",
    "        fold_rmses.append(rmse)\n",
    "        print(f\"[GroupRidge fold {fold}] RMSE={rmse:.5f}\")\n",
    "\n",
    "    te_pred = (te_sum / n_splits).astype(np.float32)\n",
    "    return oof, te_pred, fold_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e2a9d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.347691Z",
     "iopub.status.busy": "2026-02-21T02:59:16.347146Z",
     "iopub.status.idle": "2026-02-21T02:59:16.355071Z",
     "shell.execute_reply": "2026-02-21T02:59:16.354613Z"
    },
    "papermill": {
     "duration": 0.013298,
     "end_time": "2026-02-21T02:59:16.356360",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.343062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def two_stage_residual_ridge_kfold_strict(\n",
    "    Xtr, y, Xte,\n",
    "    alpha1=3000.0,\n",
    "    alpha2=1500.0,\n",
    "    n_splits=5,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Strict 2-stage residual learning under KFold:\n",
    "      - Stage1 trained on fold-train, predicts fold-val => p1_oof\n",
    "      - Residual target for stage2 uses stage1 predictions on fold-train (same fold model) => leak-free\n",
    "      - Stage2 trained on fold-train residuals, predicts fold-val residual => r_oof\n",
    "      - Final OOF = p1_oof + r_oof\n",
    "      - Test pred = fold-avg of (stage1+stage2) fold models\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    p1_oof = np.zeros(len(y), dtype=np.float32)\n",
    "    r_oof  = np.zeros(len(y), dtype=np.float32)\n",
    "    te_sum = np.zeros(Xte.shape[0], dtype=np.float64)\n",
    "    fold_rmses = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr, y), 1):\n",
    "        # ---- Stage 1 ----\n",
    "        sc1 = StandardScaler()\n",
    "        Xtr1 = sc1.fit_transform(Xtr[tr_idx])\n",
    "        Xva1 = sc1.transform(Xtr[va_idx])\n",
    "        Xte1 = sc1.transform(Xte)\n",
    "\n",
    "        m1 = Ridge(alpha=alpha1)\n",
    "        m1.fit(Xtr1, y[tr_idx])\n",
    "\n",
    "        p1_va = m1.predict(Xva1).astype(np.float32)\n",
    "        p1_oof[va_idx] = p1_va\n",
    "\n",
    "        # ---- Stage 2 (residual) ----\n",
    "        # leak-free residuals on training fold:\n",
    "        p1_tr = m1.predict(Xtr1).astype(np.float32)\n",
    "        r_tr = (y[tr_idx] - p1_tr).astype(np.float32)\n",
    "\n",
    "        sc2 = StandardScaler()\n",
    "        Xtr2 = sc2.fit_transform(Xtr[tr_idx])\n",
    "        Xva2 = sc2.transform(Xtr[va_idx])\n",
    "        Xte2 = sc2.transform(Xte)\n",
    "\n",
    "        m2 = Ridge(alpha=alpha2)\n",
    "        m2.fit(Xtr2, r_tr)\n",
    "\n",
    "        r_va = m2.predict(Xva2).astype(np.float32)\n",
    "        r_oof[va_idx] = r_va\n",
    "\n",
    "        te_fold = m1.predict(Xte1).astype(np.float64) + m2.predict(Xte2).astype(np.float64)\n",
    "        te_sum += te_fold\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y[va_idx], p1_va + r_va)))\n",
    "        fold_rmses.append(rmse)\n",
    "        print(f\"[2-stage KFold fold {fold}] RMSE={rmse:.5f}\")\n",
    "\n",
    "    te_pred = (te_sum / n_splits).astype(np.float32)\n",
    "    oof_final = (p1_oof + r_oof).astype(np.float32)\n",
    "    rmse_final = float(np.sqrt(mean_squared_error(y, oof_final)))\n",
    "    print(f\"[2-stage KFold OOF] RMSE={rmse_final:.5f}\")\n",
    "    return oof_final, te_pred, fold_rmses, rmse_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba59b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.363859Z",
     "iopub.status.busy": "2026-02-21T02:59:16.363392Z",
     "iopub.status.idle": "2026-02-21T02:59:16.370184Z",
     "shell.execute_reply": "2026-02-21T02:59:16.369666Z"
    },
    "papermill": {
     "duration": 0.011877,
     "end_time": "2026-02-21T02:59:16.371469",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.359592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ridge_kfold_predict(\n",
    "    Xtr, y, Xte,\n",
    "    n_splits=N_SPLITS,\n",
    "    seed=RANDOM_SEED,\n",
    "    alpha=ALPHA,\n",
    "    verbose=True,\n",
    "):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n",
    "    fold_scores = []\n",
    "    best_coef = None\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "        X_te_s = scaler.transform(Xte)\n",
    "\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_tr_s, y_tr)\n",
    "\n",
    "        if fold == 1:\n",
    "            best_coef = model.coef_.copy()\n",
    "\n",
    "        va_pred = model.predict(X_va_s)\n",
    "        oof[va_idx] = va_pred.astype(np.float32)\n",
    "\n",
    "        te_pred += model.predict(X_te_s).astype(np.float32) / n_splits\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "        # if verbose:\n",
    "            # print(f\"[Fold {fold}] RMSE={rmse:.5f}  ||w||={np.linalg.norm(model.coef_):.6f}\")\n",
    "\n",
    "    # 折均 RMSE（调试用）\n",
    "    mean_rmse = float(np.mean(fold_scores))\n",
    "    std_rmse  = float(np.std(fold_scores))\n",
    "\n",
    "    # 整体 OOF RMSE（正式口径）\n",
    "    rmse_oof = float(np.sqrt(mean_squared_error(y, oof)))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Fold Mean RMSE = {mean_rmse:.5f} ± {std_rmse:.5f}\")\n",
    "        print(f\"OOF RMSE       = {rmse_oof:.5f}\")\n",
    "\n",
    "    return oof, te_pred, fold_scores, best_coef, rmse_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acff503e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.378779Z",
     "iopub.status.busy": "2026-02-21T02:59:16.378415Z",
     "iopub.status.idle": "2026-02-21T02:59:16.383936Z",
     "shell.execute_reply": "2026-02-21T02:59:16.383273Z"
    },
    "papermill": {
     "duration": 0.010615,
     "end_time": "2026-02-21T02:59:16.385312",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.374697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enable\n",
    "def train_predict_three_targets(Xtr_seq, Xte_seq, t0_tr, t0_te, y_angle, y_depth, y_lr,\n",
    "                                windows=(4,8,16), w=20):\n",
    "    # 直接构造 2D 特征（不做 attention）\n",
    "    Xtr_a = append_with_t0_stats_fast(Xtr_seq, t0_tr, windows=windows, w=w)\n",
    "    Xte_a = append_with_t0_stats_fast(Xte_seq, t0_te, windows=windows, w=w)\n",
    "\n",
    "    Xtr_d = append_with_t0_stats_fast(Xtr_seq, t0_tr, windows=windows, w=w)\n",
    "    Xte_d = append_with_t0_stats_fast(Xte_seq, t0_te, windows=windows, w=w)\n",
    "\n",
    "    Xtr_l = append_with_t0_stats_fast(Xtr_seq, t0_tr, windows=windows, w=w)\n",
    "    Xte_l = append_with_t0_stats_fast(Xte_seq, t0_te, windows=windows, w=w)\n",
    "\n",
    "    _, pred_a, scores_a, _ = cv_ridge_predict(Xtr_a, y_angle, Xte_a)\n",
    "    _, pred_d, scores_d, _ = cv_ridge_predict(Xtr_d, y_depth, Xte_d)\n",
    "    _, pred_l, scores_l, _ = cv_ridge_predict(Xtr_l, y_lr,    Xte_l)\n",
    "\n",
    "    mean_of_3 = (float(np.mean(scores_a)) + float(np.mean(scores_d)) + float(np.mean(scores_l))) / 3.0\n",
    "    print(f\"[windows={windows}, w={w}] Mean-of-3 CV = {mean_of_3:.6f}\")\n",
    "\n",
    "    return pred_a, pred_d, pred_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94053963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.392678Z",
     "iopub.status.busy": "2026-02-21T02:59:16.392212Z",
     "iopub.status.idle": "2026-02-21T02:59:16.399502Z",
     "shell.execute_reply": "2026-02-21T02:59:16.398879Z"
    },
    "papermill": {
     "duration": 0.012359,
     "end_time": "2026-02-21T02:59:16.400747",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.388388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# windows\n",
    "def extract_t0_window_stats_fast(X_seq: np.ndarray, t0: np.ndarray, w: int = 20) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized t0-window stats.\n",
    "    X_seq: (N, T, F) float32/float64\n",
    "    t0:    (N,) int\n",
    "    w: window half-width, uses [t0-w, t0+w] inclusive => length <= 2w+1\n",
    "\n",
    "    Returns: (N, 2F) = [mean(F), std(F)]\n",
    "    \"\"\"\n",
    "    X = X_seq\n",
    "    N, T, F = X.shape\n",
    "    t0 = t0.astype(np.int32, copy=False)\n",
    "\n",
    "    # window bounds (inclusive)\n",
    "    l = np.clip(t0 - w, 0, T-1)\n",
    "    r = np.clip(t0 + w, 0, T-1)\n",
    "    # convert to prefix-sum slicing (exclusive right)\n",
    "    r_ex = r + 1\n",
    "    lens = (r_ex - l).astype(np.float32)  # (N,)\n",
    "\n",
    "    # prefix sums over time: P[:,t] = sum_{0..t-1}\n",
    "    P  = np.concatenate([np.zeros((N, 1, F), dtype=X.dtype), np.cumsum(X, axis=1)], axis=1)       # (N,T+1,F)\n",
    "    P2 = np.concatenate([np.zeros((N, 1, F), dtype=X.dtype), np.cumsum(X*X, axis=1)], axis=1)     # (N,T+1,F)\n",
    "\n",
    "    idx = np.arange(N)\n",
    "    sum_  = P[idx, r_ex, :] - P[idx, l, :]     # (N,F)\n",
    "    sum2_ = P2[idx, r_ex, :] - P2[idx, l, :]   # (N,F)\n",
    "\n",
    "    mean = sum_ / lens[:, None]\n",
    "    ex2  = sum2_ / lens[:, None]\n",
    "    var  = ex2 - mean * mean\n",
    "    var  = np.maximum(var, 0.0)  # numerical guard\n",
    "    std  = np.sqrt(var)\n",
    "\n",
    "    out = np.concatenate([mean, std], axis=1).astype(np.float32, copy=False)  # (N,2F)\n",
    "    return out\n",
    "\n",
    "\n",
    "def append_with_t0_stats_fast(X_seq: np.ndarray, t0: np.ndarray,\n",
    "                              windows=(4, 8, 16), w: int = 20) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return: [append_multiscale_summary(X_seq)] + [t0-window mean/std]\n",
    "    \"\"\"\n",
    "    X_base = append_multiscale_summary(X_seq, windows=windows)            # (N, big)\n",
    "    X_t0   = extract_t0_window_stats_fast(X_seq, t0, w=w)                 # (N, 2F)\n",
    "    return np.concatenate([X_base, X_t0], axis=1).astype(np.float32, copy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ad00382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.408079Z",
     "iopub.status.busy": "2026-02-21T02:59:16.407863Z",
     "iopub.status.idle": "2026-02-21T02:59:16.418327Z",
     "shell.execute_reply": "2026-02-21T02:59:16.417670Z"
    },
    "papermill": {
     "duration": 0.015795,
     "end_time": "2026-02-21T02:59:16.419708",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.403913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attention\n",
    "def kp_xyz_indices(used_kps, kp_name):\n",
    "    \"\"\"Assume X_seq feature order is [kp1_x,kp1_y,kp1_z, kp2_x,kp2_y,kp2_z, ...].\"\"\"\n",
    "    if kp_name not in used_kps:\n",
    "        return None\n",
    "    base = used_kps.index(kp_name) * 3\n",
    "    return (base, base + 1, base + 2)\n",
    "\n",
    "def _moving_average_1d(v, k):\n",
    "    # v: (N, L)\n",
    "    if k is None or k <= 1:\n",
    "        return v\n",
    "    pad = k // 2\n",
    "    v_pad = np.pad(v, ((0,0),(pad,pad)), mode=\"edge\")\n",
    "    c = np.cumsum(v_pad, axis=1)\n",
    "    return (c[:, k:] - c[:, :-k]) / k\n",
    "\n",
    "def estimate_t0_joint_peak(\n",
    "    X_seq,\n",
    "    used_kps,\n",
    "    candidates=None,\n",
    "    smooth=5,\n",
    "    return_winner=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    X_seq: (N,T,F)\n",
    "    used_kps: list of keypoint base names in the same order used in X_seq\n",
    "    candidates: list of kp names to consider. If None, use a strong default set.\n",
    "    smooth: moving-average window on speed magnitude (helps reduce jitter)\n",
    "    return_winner: also return which keypoint (string) triggered the peak for each sample\n",
    "\n",
    "    Returns:\n",
    "      t0: (N,) int  peak frame\n",
    "      winner_kp: (N,) object (optional)  name of kp that achieved max-speed at t0\n",
    "    \"\"\"\n",
    "    N, T, F = X_seq.shape\n",
    "\n",
    "    if candidates is None:\n",
    "        # High-potential release proxies: wrists + elbows + (optionally) fingertips.\n",
    "        # These names must match entries in used_kps; missing ones are auto-skipped.\n",
    "        candidates = [\n",
    "            \"right_wrist\", \"left_wrist\",\n",
    "            \"right_elbow\", \"left_elbow\",\n",
    "            # fingertip/distal joints (only used if present in used_kps)\n",
    "            \"right_index_distal\", \"left_index_distal\",\n",
    "            \"right_middle_distal\", \"left_middle_distal\",\n",
    "            \"right_ring_distal\", \"left_ring_distal\",\n",
    "            \"right_pinky_distal\", \"left_pinky_distal\",\n",
    "            \"right_thumb_distal\", \"left_thumb_distal\",\n",
    "        ]\n",
    "\n",
    "    # Keep only candidates actually present\n",
    "    present = []\n",
    "    idxs = []\n",
    "    for kp in candidates:\n",
    "        idx = kp_xyz_indices(used_kps, kp)\n",
    "        if idx is not None:\n",
    "            present.append(kp)\n",
    "            idxs.append(idx)\n",
    "\n",
    "    if len(present) == 0:\n",
    "        raise ValueError(\"None of the candidate keypoints exist in used_kps. \"\n",
    "                         \"Print used_kps[:50] and pick valid names.\")\n",
    "\n",
    "    # Compute per-kp speed magnitude: v_kp in R^{N x (T-1)}\n",
    "    v_list = []\n",
    "    for (ix, iy, iz) in idxs:\n",
    "        x = X_seq[:, :, ix]\n",
    "        y = X_seq[:, :, iy]\n",
    "        z = X_seq[:, :, iz]\n",
    "        vx = np.diff(x, axis=1)\n",
    "        vy = np.diff(y, axis=1)\n",
    "        vz = np.diff(z, axis=1)\n",
    "        v = np.sqrt(vx*vx + vy*vy + vz*vz)           # (N, T-1)\n",
    "        v = _moving_average_1d(v, smooth)            # (N, T-1)\n",
    "        v_list.append(v)\n",
    "\n",
    "    V = np.stack(v_list, axis=0)                     # (K, N, T-1)\n",
    "\n",
    "    # At each (n,t), pick kp with maximum speed; then pick time of maximum.\n",
    "    kp_arg = np.argmax(V, axis=0)                    # (N, T-1) kp index at each time\n",
    "    v_max  = np.max(V, axis=0)                       # (N, T-1) max speed at each time\n",
    "    t_peak = np.argmax(v_max, axis=1)                # (N,) index in [0..T-2]\n",
    "    t0 = (t_peak + 1).astype(np.int32)               # map to frame index [1..T-1]\n",
    "\n",
    "    if not return_winner:\n",
    "        return t0\n",
    "\n",
    "    winner_idx = kp_arg[np.arange(N), t_peak]        # (N,) kp index that won at peak time\n",
    "    winner_kp = np.array([present[i] for i in winner_idx], dtype=object)\n",
    "    return t0, winner_kp\n",
    "\n",
    "def apply_adaptive_gaussian_attention(X_seq, t0, sigma=18, k=1.35):\n",
    "    \"\"\"\n",
    "    X_seq: (N,T,F), t0: (N,)\n",
    "    Multiplies each sample by a Gaussian bump centered at its own t0.\n",
    "    \"\"\"\n",
    "    X = X_seq.copy()\n",
    "    N, T, F = X.shape\n",
    "    tt = np.arange(T)[None, :]\n",
    "    t0 = t0[:, None]\n",
    "    g = 1.0 + (k - 1.0) * np.exp(-0.5 * ((tt - t0) / sigma) ** 2)  # (N,T)\n",
    "    X *= g[:, :, None].astype(X.dtype)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc3ac6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.427335Z",
     "iopub.status.busy": "2026-02-21T02:59:16.427121Z",
     "iopub.status.idle": "2026-02-21T02:59:16.437951Z",
     "shell.execute_reply": "2026-02-21T02:59:16.437305Z"
    },
    "papermill": {
     "duration": 0.016331,
     "end_time": "2026-02-21T02:59:16.439207",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.422876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# 1) coef -> (T,F) for raw flatten part\n",
    "# -------------------------\n",
    "def ridge_unpack_raw_coef(coef_1d: np.ndarray, T: int, F: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    coef_1d: Ridge coef on X columns.\n",
    "    If you appended multiscale summary, coef_1d may be longer than T*F;\n",
    "    we only visualize the raw flatten part (first T*F).\n",
    "    \"\"\"\n",
    "    coef_1d = np.asarray(coef_1d).reshape(-1)\n",
    "    raw_len = T * F\n",
    "    if coef_1d.shape[0] < raw_len:\n",
    "        raise ValueError(f\"coef dim={coef_1d.shape[0]} < T*F={raw_len}\")\n",
    "    return coef_1d[:raw_len].reshape(T, F)\n",
    "\n",
    "# -------------------------\n",
    "# 2) aggregate over feature dims -> time importance\n",
    "# -------------------------\n",
    "def time_importance(coef_tf: np.ndarray, agg=\"l2\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    coef_tf: (T, F)\n",
    "    agg: 'l1' | 'l2' | 'max'\n",
    "    return: (T,)\n",
    "    \"\"\"\n",
    "    if agg == \"l1\":\n",
    "        return np.sum(np.abs(coef_tf), axis=1)\n",
    "    if agg == \"l2\":\n",
    "        return np.sqrt(np.sum(coef_tf**2, axis=1))\n",
    "    if agg == \"max\":\n",
    "        return np.max(np.abs(coef_tf), axis=1)\n",
    "    raise ValueError(\"agg must be one of: l1, l2, max\")\n",
    "\n",
    "# -------------------------\n",
    "# 3) plot time importance + mark peaks\n",
    "# -------------------------\n",
    "def plot_time_importance_with_peaks(coef_tf: np.ndarray, agg=\"l2\", topk=8,\n",
    "                                    title=\"Time importance (Ridge)\"):\n",
    "    imp = time_importance(coef_tf, agg=agg)\n",
    "    peaks = np.argsort(imp)[::-1][:topk]\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(imp)\n",
    "    for p in peaks:\n",
    "        plt.axvline(int(p), linestyle=\"--\", linewidth=1)\n",
    "        plt.text(int(p), float(imp[p]), f\"{int(p)}\", rotation=90,\n",
    "                 va=\"bottom\", ha=\"center\")\n",
    "    plt.xlabel(\"time index (frame)\")\n",
    "    plt.ylabel(f\"importance ({agg})\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Top peak frames:\", [(int(p), float(imp[p])) for p in peaks])\n",
    "\n",
    "# -------------------------\n",
    "# 4) heatmap view (optional but useful)\n",
    "# -------------------------\n",
    "def plot_coef_heatmap(coef_tf: np.ndarray, title=\"Coef heatmap (feature vs time)\"):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.imshow(coef_tf.T, aspect=\"auto\")  # y=feature dim, x=time\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"time index (frame)\")\n",
    "    plt.ylabel(\"feature dim (flattened)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# 5) list top-k (t,f) coefficients\n",
    "# -------------------------\n",
    "def topk_coef_entries(coef_tf: np.ndarray, k=30):\n",
    "    T, F = coef_tf.shape\n",
    "    flat = coef_tf.reshape(-1)\n",
    "    idx = np.argsort(np.abs(flat))[::-1][:k]\n",
    "    out = []\n",
    "    for j in idx:\n",
    "        t = j // F\n",
    "        f = j % F\n",
    "        out.append((int(t), int(f), float(flat[j])))\n",
    "    return out\n",
    "\n",
    "def print_topk(topk_list, feature_names=None):\n",
    "    for rank, (t, f, c) in enumerate(topk_list, 1):\n",
    "        nm = feature_names[f] if feature_names is not None else f\"f={f}\"\n",
    "        print(f\"{rank:02d}. t={t:03d}  {nm:<20}  coef={c:+.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f30da0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.446925Z",
     "iopub.status.busy": "2026-02-21T02:59:16.446519Z",
     "iopub.status.idle": "2026-02-21T02:59:16.451423Z",
     "shell.execute_reply": "2026-02-21T02:59:16.450755Z"
    },
    "papermill": {
     "duration": 0.011047,
     "end_time": "2026-02-21T02:59:16.453358",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.442311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- (ADD) Multiscale time summarization features ----\n",
    "def append_multiscale_summary(X_seq: np.ndarray, windows=(4, 8, 16)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    X_seq: (N, T, F) float32\n",
    "    Return: (N, T*F + sum_w 2*(T/w)*F) float32\n",
    "      = [raw flatten] + [block-mean] + [block-std] for each window w.\n",
    "    \"\"\"\n",
    "    assert X_seq.ndim == 3\n",
    "    N, T, F = X_seq.shape\n",
    "\n",
    "    feats = [X_seq.reshape(N, -1)]\n",
    "    for w in windows:\n",
    "        if T % w != 0:\n",
    "            continue  # only keep exact partitions\n",
    "        Xw = X_seq.reshape(N, T // w, w, F)\n",
    "        m = Xw.mean(axis=2)           # (N, T/w, F)\n",
    "        s = Xw.std(axis=2)            # (N, T/w, F)\n",
    "        feats.append(m.reshape(N, -1))\n",
    "        feats.append(s.reshape(N, -1))\n",
    "\n",
    "    return np.concatenate(feats, axis=1).astype(np.float32, copy=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2e4ce3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.460896Z",
     "iopub.status.busy": "2026-02-21T02:59:16.460660Z",
     "iopub.status.idle": "2026-02-21T02:59:16.469790Z",
     "shell.execute_reply": "2026-02-21T02:59:16.469115Z"
    },
    "papermill": {
     "duration": 0.014548,
     "end_time": "2026-02-21T02:59:16.471154",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.456606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgb_kfold_predict(\n",
    "    Xtr, y, Xte,\n",
    "    n_splits=N_SPLITS,\n",
    "    seed=RANDOM_SEED,\n",
    "    params=None,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    XGBoost KFold CV (OOF + test avg), interface aligned with ridge_kfold_predict:\n",
    "      returns (oof, te_pred, fold_scores, best_pack, rmse_oof)\n",
    "\n",
    "    Notes:\n",
    "    - No scaling needed for tree models.\n",
    "    - Uses early stopping on each fold.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    # xgboost import\n",
    "    import xgboost as xgb\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_sum = np.zeros(Xte.shape[0], dtype=np.float64)\n",
    "    fold_scores = []\n",
    "\n",
    "    # default params (safe/strong baseline for tabular regression)\n",
    "    if params is None:\n",
    "        params = dict(\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=8,\n",
    "            min_child_weight=10,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=5.0,\n",
    "            reg_alpha=0.0,\n",
    "            gamma=0.0,\n",
    "            objective=\"reg:squarederror\",\n",
    "            eval_metric=\"rmse\",\n",
    "            tree_method=\"hist\",   # fast on CPU; if GPU available you can switch to \"gpu_hist\"\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "\n",
    "    best_pack = None  # store first fold booster + best_iteration for debugging\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "\n",
    "        # early stopping via callbacks (compatible with newer xgboost)\n",
    "        callbacks = []\n",
    "        if early_stopping_rounds is not None and early_stopping_rounds > 0:\n",
    "            callbacks.append(xgb.callback.EarlyStopping(rounds=early_stopping_rounds, save_best=True))\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            verbose=False)\n",
    "\n",
    "        # predict val with best iteration\n",
    "        va_pred = model.predict(X_va).astype(np.float32)\n",
    "        oof[va_idx] = va_pred\n",
    "\n",
    "        # predict test (use same best iteration)\n",
    "        te_pred_fold = model.predict(Xte).astype(np.float64)\n",
    "        te_sum += te_pred_fold\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "        if fold == 1:\n",
    "            # keep for inspection if needed\n",
    "            best_pack = {\n",
    "                \"best_iteration\": getattr(model, \"best_iteration\", None),\n",
    "                \"best_ntree_limit\": getattr(model, \"best_ntree_limit\", None),\n",
    "                \"model\": model,\n",
    "            }\n",
    "\n",
    "        if verbose:\n",
    "            bi = getattr(model, \"best_iteration\", None)\n",
    "            if bi is None:\n",
    "                print(f\"[XGB Fold {fold}] RMSE={rmse:.5f}\")\n",
    "            else:\n",
    "                print(f\"[XGB Fold {fold}] RMSE={rmse:.5f}  best_iter={bi}\")\n",
    "\n",
    "    te_pred = (te_sum / n_splits).astype(np.float32)\n",
    "\n",
    "    rmse_oof = float(np.sqrt(mean_squared_error(y, oof)))\n",
    "    mean_rmse = float(np.mean(fold_scores))\n",
    "    std_rmse  = float(np.std(fold_scores))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Fold Mean RMSE = {mean_rmse:.5f} ± {std_rmse:.5f}\")\n",
    "        print(f\"OOF RMSE       = {rmse_oof:.5f}\")\n",
    "\n",
    "    return oof, te_pred, fold_scores, best_pack, rmse_oof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73b676",
   "metadata": {
    "papermill": {
     "duration": 0.003071,
     "end_time": "2026-02-21T02:59:16.477303",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.474232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "097cd8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.484380Z",
     "iopub.status.busy": "2026-02-21T02:59:16.484173Z",
     "iopub.status.idle": "2026-02-21T02:59:16.488017Z",
     "shell.execute_reply": "2026-02-21T02:59:16.487377Z"
    },
    "papermill": {
     "duration": 0.008818,
     "end_time": "2026-02-21T02:59:16.489292",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.480474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "    # =========================\n",
    "    # CONFIG (easy rollback)\n",
    "    # =========================\n",
    "    CFG = dict(\n",
    "        # toggles\n",
    "        MODEL = \"xgb\",  # \"ridge\" or \"xgb\"\n",
    "        USE_ANGLE_ATTENTION=True,   # set False to rollback attention\n",
    "        USE_T0_STATS=True,          # set False to rollback window stats\n",
    "        USE_ENSEMBLE=False,          # set False to rollback to single model\n",
    "\n",
    "        # angle attention params (only if USE_ANGLE_ATTENTION)\n",
    "        ANGLE_SIGMA=45,\n",
    "        ANGLE_K=1.15,\n",
    "\n",
    "        # t0-window half widths per target (only if USE_T0_STATS)\n",
    "        W_ANGLE=25,\n",
    "        W_DEPTH=15,\n",
    "        W_LR=15,\n",
    "\n",
    "        # multiscale windows\n",
    "        WINDOWS_A=(6, 12, 24),\n",
    "        WINDOWS_B=(6, 12, 24), # (4, 8, 16), (6, 12, 24) # only used if USE_ENSEMBLE\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a410c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.496720Z",
     "iopub.status.busy": "2026-02-21T02:59:16.496422Z",
     "iopub.status.idle": "2026-02-21T02:59:16.502152Z",
     "shell.execute_reply": "2026-02-21T02:59:16.501597Z"
    },
    "papermill": {
     "duration": 0.010901,
     "end_time": "2026-02-21T02:59:16.503389",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.492488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_X_for_target(Xtr_seq, Xte_seq, t0_tr, t0_te, *, target,\n",
    "                       use_t0_stats=True, windows=(6,12,24),\n",
    "                       w_angle=25, w_depth=15, w_lr=15,\n",
    "                       use_angle_attention=False, angle_sigma=45, angle_k=1.15):\n",
    "    \"\"\"\n",
    "    Returns: Xtr_2d, Xte_2d\n",
    "    target in {\"angle\",\"depth\",\"lr\"}\n",
    "    \"\"\"\n",
    "    # choose seq (possibly with attention)\n",
    "    if target == \"angle\" and use_angle_attention:\n",
    "        Xtr_s = apply_adaptive_gaussian_attention(Xtr_seq, t0_tr, sigma=angle_sigma, k=angle_k)\n",
    "        Xte_s = apply_adaptive_gaussian_attention(Xte_seq, t0_te, sigma=angle_sigma, k=angle_k)\n",
    "    else:\n",
    "        Xtr_s, Xte_s = Xtr_seq, Xte_seq\n",
    "\n",
    "    # choose window half width\n",
    "    if target == \"angle\":\n",
    "        w = w_angle\n",
    "    elif target == \"depth\":\n",
    "        w = w_depth\n",
    "    else:\n",
    "        w = w_lr\n",
    "\n",
    "    # build final 2D features\n",
    "    if use_t0_stats:\n",
    "        Xtr_2d = append_with_t0_stats_fast(Xtr_s, t0_tr, windows=windows, w=w)\n",
    "        Xte_2d = append_with_t0_stats_fast(Xte_s, t0_te, windows=windows, w=w)\n",
    "    else:\n",
    "        # rollback: multiscale only (still 2D)\n",
    "        Xtr_2d = append_multiscale_summary(Xtr_s, windows=windows)\n",
    "        Xte_2d = append_multiscale_summary(Xte_s, windows=windows)\n",
    "\n",
    "    return Xtr_2d, Xte_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c491b40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.510684Z",
     "iopub.status.busy": "2026-02-21T02:59:16.510447Z",
     "iopub.status.idle": "2026-02-21T02:59:16.528123Z",
     "shell.execute_reply": "2026-02-21T02:59:16.527640Z"
    },
    "papermill": {
     "duration": 0.022922,
     "end_time": "2026-02-21T02:59:16.529410",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.506488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Submission scaling (v02 core)\n",
    "# =========================\n",
    "def minmax_scale_clip(x, vmin, vmax):\n",
    "    x = (x - vmin) / (vmax - vmin)\n",
    "    return np.clip(x, 0.0, 1.0)\n",
    "\n",
    "def main():\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    BASE = \"/kaggle/input/spl-utspan-data-challenge-2026\"\n",
    "    TRAIN_PATH = os.path.join(BASE, \"train.csv\")\n",
    "    TEST_PATH  = os.path.join(BASE, \"test.csv\")\n",
    "    SUB_PATH   = os.path.join(BASE, \"submission.csv\")\n",
    "\n",
    "    train = pd.read_csv(TRAIN_PATH)\n",
    "    test  = pd.read_csv(TEST_PATH)\n",
    "    sub   = pd.read_csv(SUB_PATH)\n",
    "\n",
    "    keypoints = get_keypoints_from_columns(train)\n",
    "    assert len(keypoints) > 0\n",
    "    print(\"Keypoints:\", len(keypoints))\n",
    "    \n",
    "    # ---- Build features ----\n",
    "    Xtr_seq, used_kps, angle_triplets = build_fulltime_sequence(train, keypoints)\n",
    "    Xte_seq, _, _ = build_fulltime_sequence(test, keypoints)\n",
    "\n",
    "    T = Xtr_seq.shape[1]  # <<< 必须先定义\n",
    "    F = Xtr_seq.shape[2]\n",
    "\n",
    "    # ---- estimate adaptive t0 (joint peak) ----\n",
    "    t0_tr, win_tr = estimate_t0_joint_peak(Xtr_seq, used_kps, smooth=5, return_winner=True)\n",
    "    t0_te, win_te = estimate_t0_joint_peak(Xte_seq, used_kps, smooth=5, return_winner=True)\n",
    "\n",
    "    print(\"t0_tr stats (raw):\", int(t0_tr.min()), int(t0_tr.mean()), int(t0_tr.max()))\n",
    "    import collections\n",
    "    print(collections.Counter(win_tr).most_common(10))\n",
    "\n",
    "    # ---- IMPORTANT: clip t0 to avoid boundary noise (e.g. min=1) ----\n",
    "    # t0_tr = np.clip(t0_tr, 40, T-20).astype(np.int32)\n",
    "    # t0_te = np.clip(t0_te, 40, T-20).astype(np.int32)\n",
    "    # print(\"t0_tr stats (clipped):\", int(t0_tr.min()), int(t0_tr.mean()), int(t0_tr.max()))\n",
    "\n",
    "    # ---- targets ----\n",
    "    y_angle = train[\"angle\"].values.astype(np.float32)\n",
    "    y_depth = train[\"depth\"].values.astype(np.float32)\n",
    "    y_lr    = train[\"left_right\"].values.astype(np.float32)\n",
    "\n",
    "    def run_one_model(windows):\n",
    "        # build X for each target\n",
    "        Xtr_a, Xte_a = build_X_for_target(\n",
    "            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"angle\",\n",
    "            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n",
    "            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n",
    "            use_angle_attention=CFG[\"USE_ANGLE_ATTENTION\"],\n",
    "            angle_sigma=CFG[\"ANGLE_SIGMA\"], angle_k=CFG[\"ANGLE_K\"],\n",
    "        )\n",
    "        Xtr_d, Xte_d = build_X_for_target(\n",
    "            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"depth\",\n",
    "            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n",
    "            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n",
    "            use_angle_attention=False,  # only angle can use attention\n",
    "        )\n",
    "        Xtr_l, Xte_l = build_X_for_target(\n",
    "            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"lr\",\n",
    "            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n",
    "            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n",
    "            use_angle_attention=False,\n",
    "        )\n",
    "\n",
    "        # train/predict\n",
    "        if CFG.get(\"MODEL\", \"ridge\") == \"ridge\":\n",
    "            oof_a, pred_a, s_a, _, rmse_a = xgb_kfold_predict(Xtr_a, y_angle, Xte_a, seed=RANDOM_SEED)\n",
    "            oof_d, pred_d, s_d, _, rmse_d = xgb_kfold_predict(Xtr_d, y_depth, Xte_d, seed=RANDOM_SEED+1)\n",
    "            oof_l, pred_l, s_l, _, rmse_l = xgb_kfold_predict(Xtr_l, y_lr,    Xte_l, seed=RANDOM_SEED+2)\n",
    "        else:\n",
    "            oof_a, pred_a, s_a, _, rmse_a = ridge_kfold_predict(Xtr_a, y_angle, Xte_a, alpha=ALPHA, seed=RANDOM_SEED)\n",
    "            oof_d, pred_d, s_d, _, rmse_d = ridge_kfold_predict(Xtr_d, y_depth, Xte_d, alpha=ALPHA, seed=RANDOM_SEED)\n",
    "            oof_l, pred_l, s_l, _, rmse_l = ridge_kfold_predict(Xtr_l, y_lr,    Xte_l, alpha=ALPHA, seed=RANDOM_SEED)\n",
    "\n",
    "            # oof_a, pred_a, s_a, rmse_a = two_stage_residual_ridge_kfold_strict(\n",
    "                # Xtr_a, y_angle, Xte_a, alpha1=3000, alpha2=800, n_splits=5, seed=RANDOM_SEED\n",
    "            # )\n",
    "            # oof_d, pred_d, s_d, rmse_d = two_stage_residual_ridge_kfold_strict(\n",
    "                # Xtr_d, y_depth, Xte_d, alpha1=3000, alpha2=800,  n_splits=5, seed=RANDOM_SEED\n",
    "            # )\n",
    "            # oof_l, pred_l, s_l, rmse_l = two_stage_residual_ridge_kfold_strict(\n",
    "                # Xtr_l, y_lr,    Xte_l, alpha1=3000, alpha2=800, n_splits=5, seed=RANDOM_SEED\n",
    "            # )\n",
    "\n",
    "        mean_of_3 = (rmse_a + rmse_d + rmse_l) / 3.0\n",
    "        print(f\"[windows={windows}] OOF Mean-of-3 = {mean_of_3:.6f}\")\n",
    "\n",
    "        # Return fold rmses too (for debugging/compat)\n",
    "        return (pred_a, pred_d, pred_l), (s_a, s_d, s_l), (rmse_a, rmse_d, rmse_l)\n",
    "\n",
    "    if not CFG[\"USE_ENSEMBLE\"]:\n",
    "        (pred_angle, pred_depth, pred_lr), (s_a, s_d, s_l), (rmse_a, rmse_d, rmse_l) = run_one_model(CFG[\"WINDOWS_A\"])\n",
    "        print(\"\\n=== CV Summary (single, OOF) ===\")\n",
    "        print(f\"Angle RMSE: {rmse_a:.6f}\")\n",
    "        print(f\"Depth RMSE: {rmse_d:.6f}\")\n",
    "        print(f\"LR    RMSE: {rmse_l:.6f}\")\n",
    "        print(f\"Mean-of-3:  {(rmse_a + rmse_d + rmse_l)/3.0:.6f}\")\n",
    "    else:\n",
    "        (pa1, pd1, pl1), (sa1, sd1, sl1), (ra1, rd1, rl1) = run_one_model(CFG[\"WINDOWS_A\"])\n",
    "        (pa2, pd2, pl2), (sa2, sd2, sl2), (ra2, rd2, rl2) = run_one_model(CFG[\"WINDOWS_B\"])\n",
    "\n",
    "        pred_angle = 0.5 * (pa1 + pa2)\n",
    "        pred_depth = 0.5 * (pd1 + pd2)\n",
    "        pred_lr    = 0.5 * (pl1 + pl2)\n",
    "\n",
    "        # ensemble 的 OOF 指标（按两个配置平均）\n",
    "        rmse_a = 0.5 * (ra1 + ra2)\n",
    "        rmse_d = 0.5 * (rd1 + rd2)\n",
    "        rmse_l = 0.5 * (rl1 + rl2)\n",
    "\n",
    "        print(\"\\n=== CV Summary (ensemble avg of 2 configs, OOF) ===\")\n",
    "        print(f\"Angle RMSE: {rmse_a:.6f}\")\n",
    "        print(f\"Depth RMSE: {rmse_d:.6f}\")\n",
    "        print(f\"LR    RMSE: {rmse_l:.6f}\")\n",
    "        print(f\"Mean-of-3:  {(rmse_a + rmse_d + rmse_l)/3.0:.6f}\")\n",
    "\n",
    "    \n",
    "    # ---- Fill submission EXACTLY by template columns ----\n",
    "    def pick_col(sub_cols, name):\n",
    "        if f\"scaled_{name}\" in sub_cols:\n",
    "            return f\"scaled_{name}\", True\n",
    "        if name in sub_cols:\n",
    "            return name, False\n",
    "        for c in sub_cols:\n",
    "            if c != \"id\" and name in c:\n",
    "                return c, c.startswith(\"scaled_\")\n",
    "        raise ValueError(f\"Cannot find column for '{name}' in template: {list(sub_cols)}\")\n",
    "\n",
    "    cols = sub.columns\n",
    "    cA, A_scaled = pick_col(cols, \"angle\")\n",
    "    cD, D_scaled = pick_col(cols, \"depth\")\n",
    "    cL, L_scaled = pick_col(cols, \"left_right\")\n",
    "\n",
    "    if A_scaled: sub[cA] = minmax_scale_clip(pred_angle, *SCALER_BOUNDS[\"angle\"])\n",
    "    else:        sub[cA] = pred_angle\n",
    "\n",
    "    if D_scaled: sub[cD] = minmax_scale_clip(pred_depth, *SCALER_BOUNDS[\"depth\"])\n",
    "    else:        sub[cD] = pred_depth\n",
    "\n",
    "    if L_scaled: sub[cL] = minmax_scale_clip(pred_lr, *SCALER_BOUNDS[\"left_right\"])\n",
    "    else:        sub[cL] = pred_lr\n",
    "\n",
    "    # keep only template columns, in template order\n",
    "    sub = sub[cols]\n",
    "\n",
    "    # sanity checks\n",
    "    assert len(sub) == len(test)\n",
    "    assert sub.shape[1] == pd.read_csv(SUB_PATH).shape[1]\n",
    "\n",
    "    out_path = \"submission.csv\"\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(\"Saved:\", out_path, \"shape:\", sub.shape)\n",
    "    print(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fc4609c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T02:59:16.536728Z",
     "iopub.status.busy": "2026-02-21T02:59:16.536325Z",
     "iopub.status.idle": "2026-02-21T02:59:46.936844Z",
     "shell.execute_reply": "2026-02-21T02:59:46.933166Z"
    },
    "papermill": {
     "duration": 30.420297,
     "end_time": "2026-02-21T02:59:46.952826",
     "exception": false,
     "start_time": "2026-02-21T02:59:16.532529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints: 69\n",
      "t0_tr stats (raw): 1 163 234\n",
      "[('right_wrist', 259), ('left_wrist', 86)]\n",
      "Fold Mean RMSE = 2.80053 ± 0.24661\n",
      "OOF RMSE       = 2.81137\n",
      "Fold Mean RMSE = 3.49837 ± 0.29615\n",
      "OOF RMSE       = 3.51088\n",
      "Fold Mean RMSE = 3.40399 ± 0.18637\n",
      "OOF RMSE       = 3.40909\n",
      "[windows=(6, 12, 24)] OOF Mean-of-3 = 3.243781\n",
      "\n",
      "=== CV Summary (single, OOF) ===\n",
      "Angle RMSE: 2.811368\n",
      "Depth RMSE: 3.510881\n",
      "LR    RMSE: 3.409092\n",
      "Mean-of-3:  3.243781\n",
      "Saved: submission.csv shape: (113, 4)\n",
      "                                     id  scaled_angle  scaled_depth  \\\n",
      "0  d5cc9ade-6bfd-42d2-8404-99d7506e535c      0.520770      0.487105   \n",
      "1  6fb475ff-1732-42bc-8385-9f80956199fe      0.477969      0.481610   \n",
      "2  39f95c12-deab-4d77-8a9c-feecda4d5a66      0.515179      0.540309   \n",
      "3  5ec65bf7-4892-4076-a572-e01b4b8ff038      0.470096      0.542501   \n",
      "4  52ffbd2a-969c-4e52-af66-c4b4be3c3cbb      0.482992      0.591587   \n",
      "\n",
      "   scaled_left_right  \n",
      "0           0.398150  \n",
      "1           0.547909  \n",
      "2           0.494540  \n",
      "3           0.554383  \n",
      "4           0.409213  \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15218621,
     "sourceId": 126310,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.490928,
   "end_time": "2026-02-21T02:59:47.382206",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-21T02:59:11.891278",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
