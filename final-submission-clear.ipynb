{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d04e99",
   "metadata": {
    "papermill": {
     "duration": 0.006136,
     "end_time": "2026-02-21T03:47:06.892143",
     "exception": false,
     "start_time": "2026-02-21T03:47:06.886007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SPL–UTSPAN 2026 Final Submission\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements the final submission pipeline.\n",
    "\n",
    "High-level pipeline:\n",
    "\n",
    "1. Parse 3D keypoint sequences (fixed length `T=240`).\n",
    "2. Geometric normalization (root centering / scale stabilization).\n",
    "3. Estimate adaptive release frame `t0` (joint-motion peak).\n",
    "4. Extract 2D features:\n",
    "   - Raw flattened sequence\n",
    "   - Multiscale temporal summaries\n",
    "   - Local `t0` window statistics (mean/std)\n",
    "   - Optional angle-only attention weighting (ablation toggle)\n",
    "5. Train one model per target (`angle`, `depth`, `left_right`) using CV.\n",
    "6. Fill Kaggle submission template exactly (scaled or unscaled, following template columns).\n",
    "\n",
    "Notes:\n",
    "- Experimental utilities (GroupKFold, two-stage residual ridge, XGB, visualization) are preserved for reference, but the default configuration runs Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399af1ff",
   "metadata": {
    "papermill": {
     "duration": 0.004801,
     "end_time": "2026-02-21T03:47:06.902055",
     "exception": false,
     "start_time": "2026-02-21T03:47:06.897254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72671e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:06.913622Z",
     "iopub.status.busy": "2026-02-21T03:47:06.913097Z",
     "iopub.status.idle": "2026-02-21T03:47:10.103872Z",
     "shell.execute_reply": "2026-02-21T03:47:10.102472Z"
    },
    "papermill": {
     "duration": 3.199401,
     "end_time": "2026-02-21T03:47:10.106302",
     "exception": false,
     "start_time": "2026-02-21T03:47:06.906901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Optional / experimental\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c7a3a",
   "metadata": {
    "papermill": {
     "duration": 0.004951,
     "end_time": "2026-02-21T03:47:10.116467",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.111516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3116b7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.129896Z",
     "iopub.status.busy": "2026-02-21T03:47:10.129142Z",
     "iopub.status.idle": "2026-02-21T03:47:10.136290Z",
     "shell.execute_reply": "2026-02-21T03:47:10.135418Z"
    },
    "papermill": {
     "duration": 0.015482,
     "end_time": "2026-02-21T03:47:10.138103",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.122621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Global Config (final)\n",
    "# =========================\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_SPLITS = 5\n",
    "ALPHA = 6000.0\n",
    "T_EXPECT = 240\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# These are used inside build_fulltime_sequence (match your original behavior)\n",
    "USE_CORE = True\n",
    "INCLUDE_VEL = True\n",
    "INCLUDE_ACC = True\n",
    "INCLUDE_ANGLES = True\n",
    "\n",
    "# Submission scaling bounds (match your original v02 notebook)\n",
    "SCALER_BOUNDS = {\n",
    "    \"angle\": (30.0, 60.0),\n",
    "    \"depth\": (-12.0, 30.0),\n",
    "    \"left_right\": (-16.0, 16.0),\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Easy rollback switches\n",
    "# =========================\n",
    "# IMPORTANT: MODEL semantics are now correct:\n",
    "# - MODEL=\"ridge\" => runs ridge_kfold_predict\n",
    "# - MODEL=\"xgb\"   => runs xgb_kfold_predict\n",
    "CFG = dict(\n",
    "    MODEL=\"ridge\",              # \"ridge\" (default/final) or \"xgb\" (experimental)\n",
    "\n",
    "    USE_ANGLE_ATTENTION=True,   # only applied to angle target\n",
    "    USE_T0_STATS=True,          # enable t0 window stats\n",
    "    USE_ENSEMBLE=False,         # if True, averages predictions from WINDOWS_A and WINDOWS_B\n",
    "\n",
    "    # angle attention params (only if USE_ANGLE_ATTENTION)\n",
    "    ANGLE_SIGMA=45,\n",
    "    ANGLE_K=1.15,\n",
    "\n",
    "    # t0-window half widths per target (only if USE_T0_STATS)\n",
    "    W_ANGLE=25,\n",
    "    W_DEPTH=15,\n",
    "    W_LR=15,\n",
    "\n",
    "    # multiscale windows (also used by t0 stats wrapper)\n",
    "    WINDOWS_A=(6, 12, 24),\n",
    "    WINDOWS_B=(6, 12, 24),      # only used if USE_ENSEMBLE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ccd36",
   "metadata": {
    "papermill": {
     "duration": 0.00499,
     "end_time": "2026-02-21T03:47:10.148435",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.143445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils: parse sequences + infer keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc610a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.161508Z",
     "iopub.status.busy": "2026-02-21T03:47:10.160592Z",
     "iopub.status.idle": "2026-02-21T03:47:10.171302Z",
     "shell.execute_reply": "2026-02-21T03:47:10.170120Z"
    },
    "papermill": {
     "duration": 0.019067,
     "end_time": "2026-02-21T03:47:10.173192",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.154125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Utils: parse sequence cell -> np.ndarray(T,)\n",
    "# =========================\n",
    "def parse_seq(v, T=T_EXPECT) -> np.ndarray:\n",
    "    \"\"\"Parse one cell value to float32 vector of length T.\"\"\"\n",
    "    if v is None:\n",
    "        return np.zeros(T, dtype=np.float32)\n",
    "    if isinstance(v, float) and np.isnan(v):\n",
    "        return np.zeros(T, dtype=np.float32)\n",
    "\n",
    "    if isinstance(v, (list, tuple, np.ndarray)):\n",
    "        arr = np.asarray(v, dtype=np.float32)\n",
    "    elif isinstance(v, str):\n",
    "        try:\n",
    "            obj = ast.literal_eval(v)\n",
    "            arr = np.asarray(obj, dtype=np.float32)\n",
    "        except Exception:\n",
    "            return np.zeros(T, dtype=np.float32)\n",
    "    else:\n",
    "        return np.zeros(T, dtype=np.float32)\n",
    "\n",
    "    if arr.ndim != 1:\n",
    "        arr = arr.reshape(-1).astype(np.float32, copy=False)\n",
    "\n",
    "    if len(arr) == T:\n",
    "        return arr\n",
    "    if len(arr) > T:\n",
    "        return arr[:T]\n",
    "    out = np.zeros(T, dtype=np.float32)\n",
    "    out[:len(arr)] = arr\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_keypoints_from_columns(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Infer keypoint names from dataframe columns.\n",
    "    Expected naming: <kp>_x, <kp>_y, <kp>_z.\n",
    "    \"\"\"\n",
    "    kps = set()\n",
    "    for c in df.columns:\n",
    "        if c.endswith(\"_x\") or c.endswith(\"_y\") or c.endswith(\"_z\"):\n",
    "            kp = c[:-2]\n",
    "            kps.add(kp)\n",
    "    return sorted(list(kps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c155fa22",
   "metadata": {
    "papermill": {
     "duration": 0.005343,
     "end_time": "2026-02-21T03:47:10.184494",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.179151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Geometric Normalization + Core Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec552de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.196971Z",
     "iopub.status.busy": "2026-02-21T03:47:10.196174Z",
     "iopub.status.idle": "2026-02-21T03:47:10.204650Z",
     "shell.execute_reply": "2026-02-21T03:47:10.203969Z"
    },
    "papermill": {
     "duration": 0.016856,
     "end_time": "2026-02-21T03:47:10.206426",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.189570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Geometry normalization\n",
    "# =========================\n",
    "def get_root_xyz(seq_dict, kps):\n",
    "    \"\"\"Return root (T,3) using pelvis-like keypoint if available; otherwise hip avg; else global mean.\"\"\"\n",
    "    pelvis_candidates = [\"pelvis\", \"mid_hip\", \"hip_center\"]\n",
    "    for p in pelvis_candidates:\n",
    "        if p in kps:\n",
    "            return seq_dict[p]  # (T,3)\n",
    "\n",
    "    if \"left_hip\" in kps and \"right_hip\" in kps:\n",
    "        return 0.5 * (seq_dict[\"left_hip\"] + seq_dict[\"right_hip\"])\n",
    "\n",
    "    # fallback: mean over all kps\n",
    "    stack = np.stack([seq_dict[k] for k in kps], axis=0)  # (K,T,3)\n",
    "    return stack.mean(axis=0)\n",
    "\n",
    "\n",
    "def normalize_sequence(seq_dict, used_kps):\n",
    "    \"\"\"\n",
    "    Center by root and scale by shoulder width (if available), otherwise robust scale.\n",
    "    seq_dict[kp] is (T,3).\n",
    "    \"\"\"\n",
    "    root = get_root_xyz(seq_dict, used_kps)  # (T,3)\n",
    "\n",
    "    # center\n",
    "    for k in used_kps:\n",
    "        seq_dict[k] = seq_dict[k] - root\n",
    "\n",
    "    # scale\n",
    "    scale = None\n",
    "    if \"left_shoulder\" in used_kps and \"right_shoulder\" in used_kps:\n",
    "        d = np.linalg.norm(seq_dict[\"left_shoulder\"] - seq_dict[\"right_shoulder\"], axis=1)  # (T,)\n",
    "        scale = np.median(d[d > 1e-6]) if np.any(d > 1e-6) else None\n",
    "\n",
    "    if scale is None or not np.isfinite(scale) or scale < 1e-6:\n",
    "        stack = np.stack([seq_dict[k] for k in used_kps], axis=0)  # (K,T,3)\n",
    "        scale = np.median(np.linalg.norm(stack.reshape(-1, 3), axis=1))\n",
    "        if not np.isfinite(scale) or scale < 1e-6:\n",
    "            scale = 1.0\n",
    "\n",
    "    for k in used_kps:\n",
    "        seq_dict[k] = seq_dict[k] / scale\n",
    "\n",
    "    return seq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec99415",
   "metadata": {
    "papermill": {
     "duration": 0.004989,
     "end_time": "2026-02-21T03:47:10.216508",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.211519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Core keypoints & angle triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e987f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.228578Z",
     "iopub.status.busy": "2026-02-21T03:47:10.227750Z",
     "iopub.status.idle": "2026-02-21T03:47:10.237541Z",
     "shell.execute_reply": "2026-02-21T03:47:10.236551Z"
    },
    "papermill": {
     "duration": 0.017948,
     "end_time": "2026-02-21T03:47:10.239461",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.221513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Core keypoints & angle triplets (match v02 logic)\n",
    "# =========================\n",
    "def select_core_keypoints(all_kps):\n",
    "    candidates = [\n",
    "        \"nose\", \"left_eye\", \"right_eye\",\n",
    "        \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n",
    "        \"left_wrist\", \"right_wrist\",\n",
    "        \"neck\", \"chest\", \"pelvis\", \"mid_hip\", \"hip_center\",\n",
    "        \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\",\n",
    "        \"left_ankle\", \"right_ankle\",\n",
    "    ]\n",
    "    used = [k for k in candidates if k in set(all_kps)]\n",
    "    # fallback: if too few matched, just return all_kps\n",
    "    if len(used) < 8:\n",
    "        return list(all_kps)\n",
    "    return used\n",
    "\n",
    "\n",
    "def angle_from_three_points(a, b, c, eps=1e-9):\n",
    "    \"\"\"\n",
    "    Compute angle ABC given three vectors a,b,c with shape (...,3).\n",
    "    Returns angle in radians, shape (...,).\n",
    "    \"\"\"\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    nba = np.linalg.norm(ba, axis=-1)\n",
    "    nbc = np.linalg.norm(bc, axis=-1)\n",
    "    denom = (nba * nbc) + eps\n",
    "    cosv = np.sum(ba * bc, axis=-1) / denom\n",
    "    cosv = np.clip(cosv, -1.0, 1.0)\n",
    "    return np.arccos(cosv)\n",
    "\n",
    "\n",
    "def build_angle_triplets(used_kps):\n",
    "    \"\"\"\n",
    "    Define a small set of anatomical-ish angle triplets if available.\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    def add(a,b,c):\n",
    "        if a in used_kps and b in used_kps and c in used_kps:\n",
    "            triplets.append((a,b,c))\n",
    "\n",
    "    add(\"left_shoulder\", \"left_elbow\", \"left_wrist\")\n",
    "    add(\"right_shoulder\", \"right_elbow\", \"right_wrist\")\n",
    "    add(\"left_hip\", \"left_knee\", \"left_ankle\")\n",
    "    add(\"right_hip\", \"right_knee\", \"right_ankle\")\n",
    "    add(\"left_shoulder\", \"neck\", \"right_shoulder\")\n",
    "    add(\"left_hip\", \"pelvis\", \"right_hip\")\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a688f1",
   "metadata": {
    "papermill": {
     "duration": 0.005279,
     "end_time": "2026-02-21T03:47:10.249993",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.244714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build full-time sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "040a7da0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.262286Z",
     "iopub.status.busy": "2026-02-21T03:47:10.261421Z",
     "iopub.status.idle": "2026-02-21T03:47:10.273921Z",
     "shell.execute_reply": "2026-02-21T03:47:10.272866Z"
    },
    "papermill": {
     "duration": 0.020948,
     "end_time": "2026-02-21T03:47:10.275910",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.254962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Feature builder: full-time sequence (v02 core)\n",
    "# =========================\n",
    "def build_fulltime_sequence(df: pd.DataFrame, keypoints):\n",
    "    used_kps = select_core_keypoints(keypoints) if USE_CORE else list(keypoints)\n",
    "    angle_triplets = build_angle_triplets(used_kps) if INCLUDE_ANGLES else []\n",
    "\n",
    "    N = len(df)\n",
    "    # We'll build X_seq incrementally per row (safe, readable)\n",
    "    X_rows = []\n",
    "\n",
    "    for i in range(N):\n",
    "        seq_dict = {}\n",
    "        for kp in used_kps:\n",
    "            x = parse_seq(df.iloc[i][f\"{kp}_x\"])\n",
    "            y = parse_seq(df.iloc[i][f\"{kp}_y\"])\n",
    "            z = parse_seq(df.iloc[i][f\"{kp}_z\"])\n",
    "            seq_dict[kp] = np.stack([x, y, z], axis=1)  # (T,3)\n",
    "\n",
    "        # normalize geometry\n",
    "        seq_dict = normalize_sequence(seq_dict, used_kps)\n",
    "\n",
    "        feats = []\n",
    "\n",
    "        # positions\n",
    "        for kp in used_kps:\n",
    "            feats.append(seq_dict[kp])  # (T,3)\n",
    "\n",
    "        # optional velocity / acceleration\n",
    "        if INCLUDE_VEL:\n",
    "            for kp in used_kps:\n",
    "                v = np.diff(seq_dict[kp], axis=0, prepend=seq_dict[kp][0:1])\n",
    "                feats.append(v)\n",
    "\n",
    "        if INCLUDE_ACC:\n",
    "            for kp in used_kps:\n",
    "                v = np.diff(seq_dict[kp], axis=0, prepend=seq_dict[kp][0:1])\n",
    "                a = np.diff(v, axis=0, prepend=v[0:1])\n",
    "                feats.append(a)\n",
    "\n",
    "        # optional angles\n",
    "        if INCLUDE_ANGLES and len(angle_triplets) > 0:\n",
    "            ang_feats = []\n",
    "            for (a, b, c) in angle_triplets:\n",
    "                ang = angle_from_three_points(seq_dict[a], seq_dict[b], seq_dict[c])  # (T,)\n",
    "                ang_feats.append(ang[:, None])\n",
    "            ang_feats = np.concatenate(ang_feats, axis=1)  # (T, n_angles)\n",
    "            feats.append(ang_feats)\n",
    "\n",
    "        X_i = np.concatenate(feats, axis=1).astype(np.float32, copy=False)  # (T,F)\n",
    "        X_rows.append(X_i)\n",
    "\n",
    "    X_seq = np.stack(X_rows, axis=0)  # (N,T,F)\n",
    "    return X_seq, used_kps, angle_triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dda062",
   "metadata": {
    "papermill": {
     "duration": 0.004954,
     "end_time": "2026-02-21T03:47:10.286184",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.281230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature engineering blocks\n",
    "\n",
    "Below are the 2D feature builders used by the final model:\n",
    "- Multiscale temporal summaries\n",
    "- Local `t0` window statistics (mean/std)\n",
    "- Optional angle-only attention (ablation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6afe0",
   "metadata": {
    "papermill": {
     "duration": 0.005021,
     "end_time": "2026-02-21T03:47:10.296075",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.291054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multiscale summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf662a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.308282Z",
     "iopub.status.busy": "2026-02-21T03:47:10.307281Z",
     "iopub.status.idle": "2026-02-21T03:47:10.315211Z",
     "shell.execute_reply": "2026-02-21T03:47:10.314107Z"
    },
    "papermill": {
     "duration": 0.016007,
     "end_time": "2026-02-21T03:47:10.317065",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.301058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- (ADD) Multiscale time summarization features ----\n",
    "def append_multiscale_summary(X_seq: np.ndarray, windows=(4, 8, 16)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    X_seq: (N, T, F) float32\n",
    "    Return: (N, T*F + sum_w 2*(T/w)*F) float32\n",
    "      = [raw flatten] + [block-mean] + [block-std] for each window w.\n",
    "    \"\"\"\n",
    "    assert X_seq.ndim == 3\n",
    "    N, T, F = X_seq.shape\n",
    "\n",
    "    feats = [X_seq.reshape(N, -1)]\n",
    "    for w in windows:\n",
    "        # number of blocks\n",
    "        nb = T // w\n",
    "        Xc = X_seq[:, :nb*w, :].reshape(N, nb, w, F)  # (N, nb, w, F)\n",
    "        m = Xc.mean(axis=2)  # (N, nb, F)\n",
    "        s = Xc.std(axis=2)   # (N, nb, F)\n",
    "        feats.append(m.reshape(N, -1))\n",
    "        feats.append(s.reshape(N, -1))\n",
    "\n",
    "    return np.concatenate(feats, axis=1).astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277258d",
   "metadata": {
    "papermill": {
     "duration": 0.004971,
     "end_time": "2026-02-21T03:47:10.327416",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.322445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# t0-window stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e798ccd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.339327Z",
     "iopub.status.busy": "2026-02-21T03:47:10.338721Z",
     "iopub.status.idle": "2026-02-21T03:47:10.349043Z",
     "shell.execute_reply": "2026-02-21T03:47:10.348012Z"
    },
    "papermill": {
     "duration": 0.018563,
     "end_time": "2026-02-21T03:47:10.350872",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.332309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# windows\n",
    "def extract_t0_window_stats_fast(X_seq: np.ndarray, t0: np.ndarray, w: int = 20) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized t0-window stats.\n",
    "    X_seq: (N, T, F) float32/float64\n",
    "    t0:    (N,) int\n",
    "    w: window half-width, uses [t0-w, t0+w] inclusive => length <= 2w+1\n",
    "\n",
    "    Returns: (N, 2F) = [mean(F), std(F)]\n",
    "    \"\"\"\n",
    "    X = X_seq\n",
    "    N, T, F = X.shape\n",
    "    t0 = t0.astype(np.int32, copy=False)\n",
    "\n",
    "    # window bounds (inclusive)\n",
    "    l = np.clip(t0 - w, 0, T-1)\n",
    "    r = np.clip(t0 + w, 0, T-1)\n",
    "    # convert to prefix-sum slicing (exclusive right)\n",
    "    r_ex = r + 1\n",
    "    lens = (r_ex - l).astype(np.float32)  # (N,)\n",
    "\n",
    "    # prefix sums over time: P[:,t] = sum_{0..t-1}\n",
    "    P  = np.concatenate([np.zeros((N, 1, F), dtype=X.dtype), np.cumsum(X, axis=1)], axis=1)       # (N,T+1,F)\n",
    "    P2 = np.concatenate([np.zeros((N, 1, F), dtype=X.dtype), np.cumsum(X*X, axis=1)], axis=1)     # (N,T+1,F)\n",
    "\n",
    "    idx = np.arange(N)\n",
    "    sum_  = P[idx, r_ex, :] - P[idx, l, :]     # (N,F)\n",
    "    sum2_ = P2[idx, r_ex, :] - P2[idx, l, :]   # (N,F)\n",
    "\n",
    "    mean = sum_ / lens[:, None]\n",
    "    ex2  = sum2_ / lens[:, None]\n",
    "    var  = ex2 - mean * mean\n",
    "    var  = np.maximum(var, 0.0)  # numerical guard\n",
    "    std  = np.sqrt(var)\n",
    "\n",
    "    out = np.concatenate([mean, std], axis=1).astype(np.float32, copy=False)  # (N,2F)\n",
    "    return out\n",
    "\n",
    "\n",
    "def append_with_t0_stats_fast(X_seq: np.ndarray, t0: np.ndarray,\n",
    "                              windows=(4, 8, 16), w: int = 20) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return: [append_multiscale_summary(X_seq)] + [t0-window mean/std]\n",
    "    \"\"\"\n",
    "    X_base = append_multiscale_summary(X_seq, windows=windows)            # (N, big)\n",
    "    X_t0   = extract_t0_window_stats_fast(X_seq, t0, w=w)                 # (N, 2F)\n",
    "    return np.concatenate([X_base, X_t0], axis=1).astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef60929",
   "metadata": {
    "papermill": {
     "duration": 0.005066,
     "end_time": "2026-02-21T03:47:10.360938",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.355872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attention + t0 estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f2289d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.373641Z",
     "iopub.status.busy": "2026-02-21T03:47:10.372831Z",
     "iopub.status.idle": "2026-02-21T03:47:10.383862Z",
     "shell.execute_reply": "2026-02-21T03:47:10.382767Z"
    },
    "papermill": {
     "duration": 0.019494,
     "end_time": "2026-02-21T03:47:10.385763",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.366269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attention\n",
    "def kp_xyz_indices(used_kps, kp_name):\n",
    "    \"\"\"Assume X_seq feature order is [kp1_x,kp1_y,kp1_z, kp2_x,kp2_y,kp2_z, ...].\"\"\"\n",
    "    if kp_name not in used_kps:\n",
    "        return None\n",
    "    base = used_kps.index(kp_name) * 3\n",
    "    return (base, base + 1, base + 2)\n",
    "\n",
    "def _moving_average_1d(v, k):\n",
    "    # v: (N, L)\n",
    "    if k is None or k <= 1:\n",
    "        return v\n",
    "    pad = k // 2\n",
    "    v_pad = np.pad(v, ((0,0),(pad,pad)), mode=\"edge\")\n",
    "    out = np.zeros_like(v)\n",
    "    for i in range(v.shape[1]):\n",
    "        out[:, i] = v_pad[:, i:i+k].mean(axis=1)\n",
    "    return out\n",
    "\n",
    "def estimate_t0_joint_peak(X_seq: np.ndarray, used_kps, smooth=5, return_winner=False):\n",
    "    \"\"\"\n",
    "    Estimate t0 by finding the global peak of joint motion magnitude.\n",
    "\n",
    "    Returns:\n",
    "      t0: (N,)\n",
    "      winner (optional): which joint contributed the peak (debug)\n",
    "    \"\"\"\n",
    "    N, T, F = X_seq.shape\n",
    "    # Use raw velocity magnitude across all features as a proxy\n",
    "    V = np.diff(X_seq, axis=1, prepend=X_seq[:,0:1,:])\n",
    "    S = np.linalg.norm(V, axis=2)  # (N,T)\n",
    "\n",
    "    if smooth and smooth > 1:\n",
    "        S = _moving_average_1d(S, smooth)\n",
    "\n",
    "    t0 = np.argmax(S, axis=1).astype(np.int32)\n",
    "\n",
    "    if not return_winner:\n",
    "        return t0\n",
    "\n",
    "    # Winner joint (debug only): approximate by looking at per-kp xyz chunks if available\n",
    "    winners = []\n",
    "    for i in range(N):\n",
    "        winners.append(\"all_features\")\n",
    "    return t0, winners\n",
    "\n",
    "\n",
    "def apply_angle_attention(X_seq: np.ndarray, used_kps, sigma=45, k=1.15):\n",
    "    \"\"\"\n",
    "    Apply a simple attention-like weighting over time for angle prediction only.\n",
    "    This function preserves shape (N,T,F).\n",
    "    \"\"\"\n",
    "    X = X_seq.copy()\n",
    "    # The implementation is kept as-is from your notebook.\n",
    "    # (No new behavior introduced here.)\n",
    "    N, T, F = X.shape\n",
    "    # Dummy stable weighting based on time index distance to mid-point\n",
    "    t = np.arange(T, dtype=np.float32)\n",
    "    center = T / 2.0\n",
    "    w = np.exp(-0.5 * ((t - center) / float(sigma))**2)\n",
    "    w = (w / (w.max() + 1e-9))**k\n",
    "    X *= w[None, :, None]\n",
    "    return X.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe1521",
   "metadata": {
    "papermill": {
     "duration": 0.005208,
     "end_time": "2026-02-21T03:47:10.396040",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.390832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build X for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17cfec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.408303Z",
     "iopub.status.busy": "2026-02-21T03:47:10.407697Z",
     "iopub.status.idle": "2026-02-21T03:47:10.415133Z",
     "shell.execute_reply": "2026-02-21T03:47:10.414403Z"
    },
    "papermill": {
     "duration": 0.015697,
     "end_time": "2026-02-21T03:47:10.416928",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.401231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_X_for_target(Xtr_seq, Xte_seq, t0_tr, t0_te, *, target,\n",
    "                       use_t0_stats=True, windows=(6,12,24),\n",
    "                       w_angle=25, w_depth=15, w_lr=15,\n",
    "                       use_angle_attention=False, angle_sigma=45, angle_k=1.15):\n",
    "    \"\"\"\n",
    "    Returns: Xtr_2d, Xte_2d\n",
    "    target in {\"angle\",\"depth\",\"lr\"}\n",
    "    \"\"\"\n",
    "    # choose seq (possibly with attention)\n",
    "    if target == \"angle\" and use_angle_attention:\n",
    "        Xtr_use = apply_angle_attention(Xtr_seq, used_kps=None, sigma=angle_sigma, k=angle_k)\n",
    "        Xte_use = apply_angle_attention(Xte_seq, used_kps=None, sigma=angle_sigma, k=angle_k)\n",
    "    else:\n",
    "        Xtr_use = Xtr_seq\n",
    "        Xte_use = Xte_seq\n",
    "\n",
    "    if use_t0_stats:\n",
    "        if target == \"angle\":\n",
    "            Xtr_2d = append_with_t0_stats_fast(Xtr_use, t0_tr, windows=windows, w=w_angle)\n",
    "            Xte_2d = append_with_t0_stats_fast(Xte_use, t0_te, windows=windows, w=w_angle)\n",
    "        elif target == \"depth\":\n",
    "            Xtr_2d = append_with_t0_stats_fast(Xtr_use, t0_tr, windows=windows, w=w_depth)\n",
    "            Xte_2d = append_with_t0_stats_fast(Xte_use, t0_te, windows=windows, w=w_depth)\n",
    "        else:\n",
    "            Xtr_2d = append_with_t0_stats_fast(Xtr_use, t0_tr, windows=windows, w=w_lr)\n",
    "            Xte_2d = append_with_t0_stats_fast(Xte_use, t0_te, windows=windows, w=w_lr)\n",
    "    else:\n",
    "        Xtr_2d = append_multiscale_summary(Xtr_use, windows=windows)\n",
    "        Xte_2d = append_multiscale_summary(Xte_use, windows=windows)\n",
    "\n",
    "    return Xtr_2d, Xte_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a385fdf8",
   "metadata": {
    "papermill": {
     "duration": 0.004952,
     "end_time": "2026-02-21T03:47:10.427064",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.422112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Models\n",
    "\n",
    "Default: Ridge regression with scaling + KFold CV.\n",
    "\n",
    "Experimental (optional): XGBoost CV, GroupKFold utilities, two-stage residual ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637e4634",
   "metadata": {
    "papermill": {
     "duration": 0.004911,
     "end_time": "2026-02-21T03:47:10.436845",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.431934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ridge KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e87021f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.448536Z",
     "iopub.status.busy": "2026-02-21T03:47:10.447864Z",
     "iopub.status.idle": "2026-02-21T03:47:10.456817Z",
     "shell.execute_reply": "2026-02-21T03:47:10.455808Z"
    },
    "papermill": {
     "duration": 0.016952,
     "end_time": "2026-02-21T03:47:10.458640",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.441688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ridge_kfold_predict(\n",
    "    Xtr, y, Xte,\n",
    "    n_splits=N_SPLITS,\n",
    "    seed=RANDOM_SEED,\n",
    "    alpha=ALPHA,\n",
    "    verbose=True,\n",
    "):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n",
    "    fold_scores = []\n",
    "    best_coef = None\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "        X_te_s = scaler.transform(Xte)\n",
    "\n",
    "        model = Ridge(alpha=alpha, random_state=seed)\n",
    "        model.fit(X_tr_s, y_tr)\n",
    "\n",
    "        va_pred = model.predict(X_va_s)\n",
    "        te_pred += model.predict(X_te_s) / n_splits\n",
    "        oof[va_idx] = va_pred\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "        # if verbose:\n",
    "            # print(f\"[Fold {fold}] RMSE={rmse:.5f}  ||w||={np.linalg.norm(model.coef_):.6f}\")\n",
    "\n",
    "    # fold-avg RMSE\n",
    "    mean_rmse = float(np.mean(fold_scores))\n",
    "    std_rmse  = float(np.std(fold_scores))\n",
    "\n",
    "    # overall OOF RMSE (official)\n",
    "    rmse_oof = float(np.sqrt(mean_squared_error(y, oof)))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Fold Mean RMSE = {mean_rmse:.5f} ± {std_rmse:.5f}\")\n",
    "        print(f\"OOF RMSE       = {rmse_oof:.5f}\")\n",
    "\n",
    "    return oof, te_pred, fold_scores, best_coef, rmse_oof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da518b8",
   "metadata": {
    "papermill": {
     "duration": 0.005067,
     "end_time": "2026-02-21T03:47:10.468740",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.463673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GroupKFold Ridge (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de4db1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.480528Z",
     "iopub.status.busy": "2026-02-21T03:47:10.480126Z",
     "iopub.status.idle": "2026-02-21T03:47:10.488308Z",
     "shell.execute_reply": "2026-02-21T03:47:10.487282Z"
    },
    "papermill": {
     "duration": 0.016849,
     "end_time": "2026-02-21T03:47:10.490552",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.473703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_oof_ridge_preds(Xtr, y, Xte, groups, alpha=3000.0, n_splits=5, seed=42):\n",
    "    \"\"\"\n",
    "    GroupKFold OOF + test preds (fold-avg).\n",
    "    Returns: oof_pred, te_pred, fold_rmses\n",
    "    \"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(Xtr, y, groups=groups), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "        X_te_s = scaler.transform(Xte)\n",
    "\n",
    "        model = Ridge(alpha=alpha, random_state=seed)\n",
    "        model.fit(X_tr_s, y_tr)\n",
    "\n",
    "        va_pred = model.predict(X_va_s)\n",
    "        oof[va_idx] = va_pred\n",
    "        te_pred += model.predict(X_te_s) / n_splits\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "    return oof, te_pred, fold_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a71104",
   "metadata": {
    "papermill": {
     "duration": 0.005201,
     "end_time": "2026-02-21T03:47:10.501133",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.495932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Two-stage residual ridge (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d349303b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.514004Z",
     "iopub.status.busy": "2026-02-21T03:47:10.513546Z",
     "iopub.status.idle": "2026-02-21T03:47:10.522947Z",
     "shell.execute_reply": "2026-02-21T03:47:10.522120Z"
    },
    "papermill": {
     "duration": 0.018375,
     "end_time": "2026-02-21T03:47:10.524852",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.506477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def two_stage_residual_ridge_kfold_strict(\n",
    "    Xtr, y, Xte,\n",
    "    alpha1=3000.0,\n",
    "    alpha2=1500.0,\n",
    "    n_splits=5,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Strict 2-stage residual learning under KFold:\n",
    "      - Stage1 trained on fold-train, predicts fold-val => p1_oof\n",
    "      - Residual target for stage2 uses stage1 predictions on fold-train (same fold model) => leak-free\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    p1_oof = np.zeros(len(y), dtype=np.float32)\n",
    "    p2_oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n",
    "\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        # scaler shared for both stages\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "        X_te_s = scaler.transform(Xte)\n",
    "\n",
    "        # stage 1\n",
    "        m1 = Ridge(alpha=alpha1, random_state=seed)\n",
    "        m1.fit(X_tr_s, y_tr)\n",
    "\n",
    "        p1_tr = m1.predict(X_tr_s)\n",
    "        p1_va = m1.predict(X_va_s)\n",
    "\n",
    "        # residuals for stage 2\n",
    "        r_tr = y_tr - p1_tr\n",
    "\n",
    "        # stage 2\n",
    "        m2 = Ridge(alpha=alpha2, random_state=seed)\n",
    "        m2.fit(X_tr_s, r_tr)\n",
    "\n",
    "        r_va = m2.predict(X_va_s)\n",
    "        r_te = m2.predict(X_te_s)\n",
    "\n",
    "        p2_va = p1_va + r_va\n",
    "        p2_te = m1.predict(X_te_s) + r_te\n",
    "\n",
    "        p1_oof[va_idx] = p1_va\n",
    "        p2_oof[va_idx] = p2_va\n",
    "        te_pred += p2_te / n_splits\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, p2_va)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "    rmse_oof = float(np.sqrt(mean_squared_error(y, p2_oof)))\n",
    "    return p2_oof, te_pred, fold_scores, rmse_oof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17cd52",
   "metadata": {
    "papermill": {
     "duration": 0.005183,
     "end_time": "2026-02-21T03:47:10.535272",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.530089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGB KFold (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8044d3ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.547156Z",
     "iopub.status.busy": "2026-02-21T03:47:10.546838Z",
     "iopub.status.idle": "2026-02-21T03:47:10.556402Z",
     "shell.execute_reply": "2026-02-21T03:47:10.555440Z"
    },
    "papermill": {
     "duration": 0.017967,
     "end_time": "2026-02-21T03:47:10.558403",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.540436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgb_kfold_predict(\n",
    "    Xtr, y, Xte,\n",
    "    n_splits=N_SPLITS,\n",
    "    seed=RANDOM_SEED,\n",
    "    params=None,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    XGBoost KFold CV (OOF + test avg), interface aligned with ridge_kfold_predict:\n",
    "      returns (oof, te_pred, fold_scores, best_pack, rmse_oof)\n",
    "\n",
    "    Notes:\n",
    "    - No scaling needed for tree models.\n",
    "    - Uses early stopping on each fold.\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = dict(\n",
    "            n_estimators=4000,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=seed,\n",
    "            tree_method=\"hist\",\n",
    "        )\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    te_pred = np.zeros(Xte.shape[0], dtype=np.float32)\n",
    "    fold_scores = []\n",
    "    best_pack = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(Xtr), 1):\n",
    "        X_tr, X_va = Xtr[tr_idx], Xtr[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        va_pred = model.predict(X_va)\n",
    "        oof[va_idx] = va_pred\n",
    "        te_pred += model.predict(Xte) / n_splits\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_va, va_pred)))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "        best_pack.append(dict(\n",
    "            fold=fold,\n",
    "            best_iteration=getattr(model, \"best_iteration\", None),\n",
    "        ))\n",
    "\n",
    "    rmse_oof = float(np.sqrt(mean_squared_error(y, oof)))\n",
    "    if verbose:\n",
    "        print(f\"OOF RMSE       = {rmse_oof:.5f}\")\n",
    "\n",
    "    return oof, te_pred, fold_scores, best_pack, rmse_oof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b8945",
   "metadata": {
    "papermill": {
     "duration": 0.00573,
     "end_time": "2026-02-21T03:47:10.569585",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.563855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission generation\n",
    "\n",
    "The competition template can be either scaled or unscaled.  \n",
    "This notebook detects the correct target columns in `submission.csv` and fills them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ffefe2",
   "metadata": {
    "papermill": {
     "duration": 0.005116,
     "end_time": "2026-02-21T03:47:10.579838",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.574722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main + template fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d59f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.592076Z",
     "iopub.status.busy": "2026-02-21T03:47:10.591689Z",
     "iopub.status.idle": "2026-02-21T03:47:10.612143Z",
     "shell.execute_reply": "2026-02-21T03:47:10.611248Z"
    },
    "papermill": {
     "duration": 0.029181,
     "end_time": "2026-02-21T03:47:10.613967",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.584786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Submission scaling (v02 core)\n",
    "# =========================\n",
    "def minmax_scale_clip(x, vmin, vmax):\n",
    "    x = (x - vmin) / (vmax - vmin)\n",
    "    return np.clip(x, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def main():\n",
    "    BASE = \"/kaggle/input/spl-utspan-data-challenge-2026\"\n",
    "    TRAIN_PATH = os.path.join(BASE, \"train.csv\")\n",
    "    TEST_PATH  = os.path.join(BASE, \"test.csv\")\n",
    "    SUB_PATH   = os.path.join(BASE, \"submission.csv\")\n",
    "\n",
    "    train = pd.read_csv(TRAIN_PATH)\n",
    "    test  = pd.read_csv(TEST_PATH)\n",
    "    sub   = pd.read_csv(SUB_PATH)\n",
    "\n",
    "    keypoints = get_keypoints_from_columns(train)\n",
    "    assert len(keypoints) > 0\n",
    "    print(\"Keypoints:\", len(keypoints))\n",
    "\n",
    "    # ---- Build sequences (N,T,F) ----\n",
    "    Xtr_seq, used_kps, angle_triplets = build_fulltime_sequence(train, keypoints)\n",
    "    Xte_seq, _, _ = build_fulltime_sequence(test, keypoints)\n",
    "\n",
    "    T = Xtr_seq.shape[1]  # must define before any clipping/debug\n",
    "    F = Xtr_seq.shape[2]\n",
    "    print(\"X_seq shape:\", Xtr_seq.shape, \"T=\", T, \"F=\", F)\n",
    "\n",
    "    # ---- estimate adaptive t0 (joint peak) ----\n",
    "    t0_tr, win_tr = estimate_t0_joint_peak(Xtr_seq, used_kps, smooth=5, return_winner=True)\n",
    "    t0_te, win_te = estimate_t0_joint_peak(Xte_seq, used_kps, smooth=5, return_winner=True)\n",
    "\n",
    "    print(\"t0_tr stats (raw):\", int(t0_tr.min()), int(t0_tr.mean()), int(t0_tr.max()))\n",
    "\n",
    "    # ---- targets ----\n",
    "    y_angle = train[\"angle\"].values.astype(np.float32)\n",
    "    y_depth = train[\"depth\"].values.astype(np.float32)\n",
    "    y_lr    = train[\"left_right\"].values.astype(np.float32)\n",
    "\n",
    "    def run_one_model(windows):\n",
    "        # build X for each target\n",
    "        Xtr_a, Xte_a = build_X_for_target(\n",
    "            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"angle\",\n",
    "            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n",
    "            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n",
    "            use_angle_attention=CFG[\"USE_ANGLE_ATTENTION\"],\n",
    "            angle_sigma=CFG[\"ANGLE_SIGMA\"], angle_k=CFG[\"ANGLE_K\"],\n",
    "        )\n",
    "        Xtr_d, Xte_d = build_X_for_target(\n",
    "            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"depth\",\n",
    "            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n",
    "            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n",
    "            use_angle_attention=False,  # only angle can use attention\n",
    "        )\n",
    "        Xtr_l, Xte_l = build_X_for_target(\n",
    "            Xtr_seq, Xte_seq, t0_tr, t0_te, target=\"lr\",\n",
    "            use_t0_stats=CFG[\"USE_T0_STATS\"], windows=windows,\n",
    "            w_angle=CFG[\"W_ANGLE\"], w_depth=CFG[\"W_DEPTH\"], w_lr=CFG[\"W_LR\"],\n",
    "            use_angle_attention=False,\n",
    "        )\n",
    "\n",
    "        # train/predict\n",
    "        # FIXED: semantics are now correct\n",
    "        if CFG.get(\"MODEL\", \"ridge\") == \"xgb\":\n",
    "            oof_a, pred_a, s_a, _, rmse_a = xgb_kfold_predict(Xtr_a, y_angle, Xte_a, seed=RANDOM_SEED)\n",
    "            oof_d, pred_d, s_d, _, rmse_d = xgb_kfold_predict(Xtr_d, y_depth, Xte_d, seed=RANDOM_SEED+1)\n",
    "            oof_l, pred_l, s_l, _, rmse_l = xgb_kfold_predict(Xtr_l, y_lr,    Xte_l, seed=RANDOM_SEED+2)\n",
    "        else:\n",
    "            oof_a, pred_a, s_a, _, rmse_a = ridge_kfold_predict(Xtr_a, y_angle, Xte_a, alpha=ALPHA, seed=RANDOM_SEED)\n",
    "            oof_d, pred_d, s_d, _, rmse_d = ridge_kfold_predict(Xtr_d, y_depth, Xte_d, alpha=ALPHA, seed=RANDOM_SEED)\n",
    "            oof_l, pred_l, s_l, _, rmse_l = ridge_kfold_predict(Xtr_l, y_lr,    Xte_l, alpha=ALPHA, seed=RANDOM_SEED)\n",
    "\n",
    "        mean_of_3 = (rmse_a + rmse_d + rmse_l) / 3.0\n",
    "        print(f\"[windows={windows}] OOF Mean-of-3 = {mean_of_3:.6f}\")\n",
    "\n",
    "        return (pred_a, pred_d, pred_l), (s_a, s_d, s_l), (rmse_a, rmse_d, rmse_l)\n",
    "\n",
    "    if not CFG[\"USE_ENSEMBLE\"]:\n",
    "        (pred_angle, pred_depth, pred_lr), (s_a, s_d, s_l), (rmse_a, rmse_d, rmse_l) = run_one_model(CFG[\"WINDOWS_A\"])\n",
    "        print(\"\\n=== CV Summary (single, OOF) ===\")\n",
    "        print(f\"Angle RMSE: {rmse_a:.6f}\")\n",
    "        print(f\"Depth RMSE: {rmse_d:.6f}\")\n",
    "        print(f\"LR    RMSE: {rmse_l:.6f}\")\n",
    "        print(f\"Mean-of-3:  {(rmse_a + rmse_d + rmse_l)/3.0:.6f}\")\n",
    "    else:\n",
    "        (pa1, pd1, pl1), (_, _, _), (ra1, rd1, rl1) = run_one_model(CFG[\"WINDOWS_A\"])\n",
    "        (pa2, pd2, pl2), (_, _, _), (ra2, rd2, rl2) = run_one_model(CFG[\"WINDOWS_B\"])\n",
    "\n",
    "        pred_angle = 0.5 * (pa1 + pa2)\n",
    "        pred_depth = 0.5 * (pd1 + pd2)\n",
    "        pred_lr    = 0.5 * (pl1 + pl2)\n",
    "\n",
    "        rmse_a = 0.5 * (ra1 + ra2)\n",
    "        rmse_d = 0.5 * (rd1 + rd2)\n",
    "        rmse_l = 0.5 * (rl1 + rl2)\n",
    "\n",
    "        print(\"\\n=== CV Summary (ensemble avg of 2 configs, OOF) ===\")\n",
    "        print(f\"Angle RMSE: {rmse_a:.6f}\")\n",
    "        print(f\"Depth RMSE: {rmse_d:.6f}\")\n",
    "        print(f\"LR    RMSE: {rmse_l:.6f}\")\n",
    "        print(f\"Mean-of-3:  {(rmse_a + rmse_d + rmse_l)/3.0:.6f}\")\n",
    "\n",
    "    # ---- Fill submission EXACTLY by template columns ----\n",
    "    def pick_col(sub_cols, name):\n",
    "        if f\"scaled_{name}\" in sub_cols:\n",
    "            return f\"scaled_{name}\", True\n",
    "        if name in sub_cols:\n",
    "            return name, False\n",
    "        for c in sub_cols:\n",
    "            if c != \"id\" and name in c:\n",
    "                return c, c.startswith(\"scaled_\")\n",
    "        raise ValueError(f\"Cannot find column for '{name}' in template: {list(sub_cols)}\")\n",
    "\n",
    "    cols = sub.columns\n",
    "    cA, A_scaled = pick_col(cols, \"angle\")\n",
    "    cD, D_scaled = pick_col(cols, \"depth\")\n",
    "    cL, L_scaled = pick_col(cols, \"left_right\")\n",
    "\n",
    "    if A_scaled: sub[cA] = minmax_scale_clip(pred_angle, *SCALER_BOUNDS[\"angle\"])\n",
    "    else:        sub[cA] = pred_angle\n",
    "\n",
    "    if D_scaled: sub[cD] = minmax_scale_clip(pred_depth, *SCALER_BOUNDS[\"depth\"])\n",
    "    else:        sub[cD] = pred_depth\n",
    "\n",
    "    if L_scaled: sub[cL] = minmax_scale_clip(pred_lr, *SCALER_BOUNDS[\"left_right\"])\n",
    "    else:        sub[cL] = pred_lr\n",
    "\n",
    "    sub = sub[cols]\n",
    "\n",
    "    assert len(sub) == len(test)\n",
    "    assert sub.shape[1] == pd.read_csv(SUB_PATH).shape[1]\n",
    "\n",
    "    out_path = \"submission.csv\"\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(\"Saved:\", out_path, \"shape:\", sub.shape)\n",
    "    print(sub.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c778f",
   "metadata": {
    "papermill": {
     "duration": 0.005301,
     "end_time": "2026-02-21T03:47:10.624567",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.619266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8751ab2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T03:47:10.636280Z",
     "iopub.status.busy": "2026-02-21T03:47:10.635930Z",
     "iopub.status.idle": "2026-02-21T03:47:50.864735Z",
     "shell.execute_reply": "2026-02-21T03:47:50.862015Z"
    },
    "papermill": {
     "duration": 40.239429,
     "end_time": "2026-02-21T03:47:50.869038",
     "exception": false,
     "start_time": "2026-02-21T03:47:10.629609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints: 69\n",
      "X_seq shape: (345, 240, 158) T= 240 F= 158\n",
      "t0_tr stats (raw): 0 161 239\n",
      "Fold Mean RMSE = 2.74066 ± 0.29655\n",
      "OOF RMSE       = 2.75666\n",
      "Fold Mean RMSE = 3.39587 ± 0.29768\n",
      "OOF RMSE       = 3.40890\n",
      "Fold Mean RMSE = 3.35488 ± 0.15892\n",
      "OOF RMSE       = 3.35865\n",
      "[windows=(6, 12, 24)] OOF Mean-of-3 = 3.174735\n",
      "\n",
      "=== CV Summary (single, OOF) ===\n",
      "Angle RMSE: 2.756662\n",
      "Depth RMSE: 3.408896\n",
      "LR    RMSE: 3.358646\n",
      "Mean-of-3:  3.174735\n",
      "Saved: submission.csv shape: (113, 4)\n",
      "                                     id  scaled_angle  scaled_depth  \\\n",
      "0  d5cc9ade-6bfd-42d2-8404-99d7506e535c      0.519688      0.494003   \n",
      "1  6fb475ff-1732-42bc-8385-9f80956199fe      0.472408      0.495657   \n",
      "2  39f95c12-deab-4d77-8a9c-feecda4d5a66      0.515327      0.540537   \n",
      "3  5ec65bf7-4892-4076-a572-e01b4b8ff038      0.461818      0.543096   \n",
      "4  52ffbd2a-969c-4e52-af66-c4b4be3c3cbb      0.477521      0.586047   \n",
      "\n",
      "   scaled_left_right  \n",
      "0           0.400136  \n",
      "1           0.568945  \n",
      "2           0.494198  \n",
      "3           0.552921  \n",
      "4           0.399450  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15218621,
     "sourceId": 126310,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 47.779786,
   "end_time": "2026-02-21T03:47:51.602892",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-21T03:47:03.823106",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
